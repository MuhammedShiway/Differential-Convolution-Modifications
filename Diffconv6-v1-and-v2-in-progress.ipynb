{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> IMPORT MODULES </center> ","metadata":{}},{"cell_type":"code","source":"import torch\nimport pprint\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\n\nimport wandb\nfrom wandb.keras import WandbCallback\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-23T10:50:24.479885Z","iopub.execute_input":"2023-04-23T10:50:24.480317Z","iopub.status.idle":"2023-04-23T10:50:32.858068Z","shell.execute_reply.started":"2023-04-23T10:50:24.480279Z","shell.execute_reply":"2023-04-23T10:50:32.856953Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# <center> DIFFERENTIAL CONVOLUTION </center>","metadata":{}},{"cell_type":"code","source":"# [-765 to 255]  --> [-255 to 85] --> [0 to 255]\nclass DiffConv6_1(nn.Module):\n\n    def __init__(self):\n        super(DiffConv6_1, self).__init__()\n\n    def forward(self, x):\n        sizeofin = x.size()\n        \n        ins = sizeofin[0]\n        n = sizeofin[1]\n        sx = sizeofin[2]\n        sy = sizeofin[3]  \n\n        self.output = torch.zeros(ins,n*6,sx,sy, device = x.device)\n        dmax = x.max()\n        dmin = x.min()\n        \n        for i in range(0,ins):\n\n\n            # ORIGINAL INPUT\n            oM = 0\n            oN = n\n            \n            self.output[i,oM:oN,0:sx,0:sy]= x[i].clone()\n            \n            # HORIZONTAL DIFFERENCE\n            oM = n\n            oN = 2*n\n\n            #area = self.output[i,oM:oN,0:sx-1,0:sy]\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(x[i,0:n,0:sx-1,0:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(-x[i,0:n,1:sx,0:sy])\n            \n            # VERTICAL DIFFERENCE\n            oM = 2*n\n            oN = 3*n\n\n            #area = ptr[oM:oN,0:sx,0:sy-1]\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(x[i,0:n,0:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(-x[i,0:n,0:sx,1:sy])\n            \n            # SOUTH EAST\n            oM = 3*n\n            oN = 4*n\n\n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            # SOUTH WEST\n            oM = 4*n\n            oN = 5*n\n           \n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            \n            # RIGHT - SOUTH EAST - BOTTOM\n            oM = 5*n\n            oN = 6*n\n           \n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n                        \n            # Scale: [-765 to 255]  --> [-255 to 85]\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = ( (self.output[i,oM:oN,0:sx-1,0:sy-1].clone().detach()) / 3 ).int()\n            \n\n        oM = n\n        oN = 6*n\n\n           \n        #self.signInputs = self.output.sign()\n        #self.signInputs[0:ins,0:n,:,:] = torch.ones(ins,n,sx,sy)\n        \n        #Inplace error came from the line below\n        #self.output[0:ins,oM:oN,:,:] = self.output[0:ins,oM:oN].abs()\n        self.output[0:ins,oM:oN,:,:] = torch.abs(self.output[0:ins,oM:oN].clone().detach())\n        \n        #self.output[0:ins,oM:oN,:,:] = torch.sqrt(self.output[0:ins,oM:oN] * self.output[0:ins,oM:oN].clone().detach())\n\n        #print(self.output)\n\n        return self.output","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:55:48.627503Z","iopub.execute_input":"2023-04-23T10:55:48.627959Z","iopub.status.idle":"2023-04-23T10:55:48.652259Z","shell.execute_reply.started":"2023-04-23T10:55:48.627917Z","shell.execute_reply":"2023-04-23T10:55:48.650843Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# [-765 to 765]  --> [-255 to 255] --> [0 to 255]\n\nclass DiffConv6_2(nn.Module):\n\n    def __init__(self):\n        super(DiffConv6_2, self).__init__()\n\n    def forward(self, x):\n        sizeofin = x.size()\n        \n        ins = sizeofin[0]\n        n = sizeofin[1]\n        sx = sizeofin[2]\n        sy = sizeofin[3]  \n\n        self.output = torch.zeros(ins,n*6,sx,sy, device = x.device)\n        dmax = x.max()\n        dmin = x.min()\n        \n        for i in range(0,ins):\n\n\n            # ORIGINAL INPUT\n            oM = 0\n            oN = n\n            \n            self.output[i,oM:oN,0:sx,0:sy]= x[i].clone()\n            \n            # HORIZONTAL DIFFERENCE\n            oM = n\n            oN = 2*n\n\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(x[i,0:n,0:sx-1,0:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(-x[i,0:n,1:sx,0:sy])\n            \n            # VERTICAL DIFFERENCE\n            oM = 2*n\n            oN = 3*n\n\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(x[i,0:n,0:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(-x[i,0:n,0:sx,1:sy])\n            \n            # SOUTH EAST\n            oM = 3*n\n            oN = 4*n\n\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            # SOUTH WEST\n            oM = 4*n\n            oN = 5*n\n           \n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            \n            # RIGHT - SOUTH EAST - BOTTOM\n            oM = 5*n\n            oN = 6*n\n           \n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(3*x[i,0:n,0:sx-1,0:sy-1]) # current pixel * 3\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            # [-765 to 765]  --> [-255 to 255] --> [0 to 255]\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = ( (self.output[i,oM:oN,0:sx-1,0:sy-1].clone().detach()) / 3 ).int()\n            \n\n        oM = n\n        oN = 6*n\n\n           \n        #self.signInputs = self.output.sign()\n        #self.signInputs[0:ins,0:n,:,:] = torch.ones(ins,n,sx,sy)\n        \n        #Inplace error came from the line below\n        #self.output[0:ins,oM:oN,:,:] = self.output[0:ins,oM:oN].abs()\n        self.output[0:ins,oM:oN,:,:] = torch.abs(self.output[0:ins,oM:oN].clone().detach())\n        \n        #self.output[0:ins,oM:oN,:,:] = torch.sqrt(self.output[0:ins,oM:oN] * self.output[0:ins,oM:oN].clone().detach())\n\n        #print(self.output)\n\n        return self.output","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:55:49.628849Z","iopub.execute_input":"2023-04-23T10:55:49.629225Z","iopub.status.idle":"2023-04-23T10:55:49.652514Z","shell.execute_reply.started":"2023-04-23T10:55:49.629191Z","shell.execute_reply":"2023-04-23T10:55:49.651396Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# [-765 to 255]  --> [-510 to 510] --> [-255 to 255] --> [0 to 255]\n\nclass DiffConv6_3(nn.Module):\n\n    def __init__(self):\n        super(DiffConv6_3, self).__init__()\n\n    def forward(self, x):\n        sizeofin = x.size()\n        \n        ins = sizeofin[0]\n        n = sizeofin[1]\n        sx = sizeofin[2]\n        sy = sizeofin[3]  \n\n        self.output = torch.zeros(ins,n*6,sx,sy, device = x.device)\n        dmax = x.max()\n        dmin = x.min()\n        \n        for i in range(0,ins):\n\n\n            # ORIGINAL INPUT\n            oM = 0\n            oN = n\n            \n            self.output[i,oM:oN,0:sx,0:sy]= x[i].clone()\n            \n            # HORIZONTAL DIFFERENCE\n            oM = n\n            oN = 2*n\n\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(x[i,0:n,0:sx-1,0:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(-x[i,0:n,1:sx,0:sy])\n            \n            # VERTICAL DIFFERENCE\n            oM = 2*n\n            oN = 3*n\n\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(x[i,0:n,0:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(-x[i,0:n,0:sx,1:sy])\n            \n            # SOUTH EAST\n            oM = 3*n\n            oN = 4*n\n\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            # SOUTH WEST\n            oM = 4*n\n            oN = 5*n\n           \n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            \n            # RIGHT - SOUTH EAST - BOTTOM\n            oM = 5*n\n            oN = 6*n\n           \n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1]) \n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            # [-765 to 255]  --> [-510 to 510] --> [0 to 255]\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = ( ((self.output[i,oM:oN,0:sx-1,0:sy-1].clone().detach()) + 255) / 2).int()\n            \n\n        oM = n\n        oN = 6*n\n\n           \n        #self.signInputs = self.output.sign()\n        #self.signInputs[0:ins,0:n,:,:] = torch.ones(ins,n,sx,sy)\n        \n        #Inplace error came from the line below\n        #self.output[0:ins,oM:oN,:,:] = self.output[0:ins,oM:oN].abs()\n        self.output[0:ins,oM:oN,:,:] = torch.abs(self.output[0:ins,oM:oN].clone().detach())\n        \n        #self.output[0:ins,oM:oN,:,:] = torch.sqrt(self.output[0:ins,oM:oN] * self.output[0:ins,oM:oN].clone().detach())\n\n        #print(self.output)\n\n        return self.output","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:55:50.617997Z","iopub.execute_input":"2023-04-23T10:55:50.619902Z","iopub.status.idle":"2023-04-23T10:55:50.641579Z","shell.execute_reply.started":"2023-04-23T10:55:50.619852Z","shell.execute_reply":"2023-04-23T10:55:50.640480Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# <center> DATASET </center>","metadata":{}},{"cell_type":"code","source":"# Define transforms for data preprocessing\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n])\n\n# Load CIFAR10 dataset\ntrain_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntest_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:55:56.747232Z","iopub.execute_input":"2023-04-23T10:55:56.748112Z","iopub.status.idle":"2023-04-23T10:55:58.304134Z","shell.execute_reply.started":"2023-04-23T10:55:56.748076Z","shell.execute_reply":"2023-04-23T10:55:58.303000Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <center> Network Architectures </center>","metadata":{}},{"cell_type":"code","source":"multiplier = 4\n\n# CNN with DiffConv6_1\nclass NetDiffConv6_1(nn.Module):\n    def __init__(self):\n        super(NetDiffConv6_1, self).__init__()\n        \n        self.diff = DiffConv6_1()\n        \n        self.conv1 = nn.Conv2d(18, 16*multiplier, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(16*multiplier)\n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.conv2 = nn.Conv2d(16*multiplier, 32*multiplier, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(32*multiplier)\n        \n        self.conv3 = nn.Conv2d(32*multiplier, 64*multiplier, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(64*multiplier)\n        \n        self.fc1 = nn.Linear(64*multiplier * 4 * 4, 256*multiplier)\n        self.dropout1 = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(256*multiplier, 128*multiplier)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.fc3 = nn.Linear(128*multiplier, 10)\n        \n    def forward(self, x):\n        x = self.diff(x)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x) # 16x16\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x) # 8x8\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x) # 4x4\n\n        x = x.view(-1, 64*multiplier * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x\n\n\n# CNN with DiffConv6_2\nclass NetDiffConv6_2(nn.Module):\n    def __init__(self):\n        super(NetDiffConv6_2, self).__init__()\n        \n        self.diff = DiffConv6_2()\n        \n        self.conv1 = nn.Conv2d(18, 16*multiplier, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(16*multiplier)\n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.conv2 = nn.Conv2d(16*multiplier, 32*multiplier, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(32*multiplier)\n        \n        self.conv3 = nn.Conv2d(32*multiplier, 64*multiplier, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(64*multiplier)\n        \n        self.fc1 = nn.Linear(64*multiplier * 4 * 4, 256*multiplier)\n        self.dropout1 = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(256*multiplier, 128*multiplier)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.fc3 = nn.Linear(128*multiplier, 10)\n        \n    def forward(self, x):\n        x = self.diff(x)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x) # 16x16\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x) # 8x8\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x) # 4x4\n\n        x = x.view(-1, 64*multiplier * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x\n\n# CNN with DiffConv6_3\nclass NetDiffConv6_3(nn.Module):\n    def __init__(self):\n        super(NetDiffConv6_3, self).__init__()\n        \n        self.diff = DiffConv6_3()\n        \n        self.conv1 = nn.Conv2d(18, 16*multiplier, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(16*multiplier)\n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.conv2 = nn.Conv2d(16*multiplier, 32*multiplier, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(32*multiplier)\n        \n        self.conv3 = nn.Conv2d(32*multiplier, 64*multiplier, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(64*multiplier)\n        \n        self.fc1 = nn.Linear(64*multiplier * 4 * 4, 256*multiplier)\n        self.dropout1 = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(256*multiplier, 128*multiplier)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.fc3 = nn.Linear(128*multiplier, 10)\n        \n    def forward(self, x):\n        x = self.diff(x)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x) # 16x16\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x) # 8x8\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x) # 4x4\n\n        x = x.view(-1, 64*multiplier * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:55:59.479358Z","iopub.execute_input":"2023-04-23T10:55:59.479757Z","iopub.status.idle":"2023-04-23T10:55:59.505247Z","shell.execute_reply.started":"2023-04-23T10:55:59.479721Z","shell.execute_reply":"2023-04-23T10:55:59.504256Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# <center> WandB Config </center>","metadata":{}},{"cell_type":"code","source":"# Set up Weights and Biases\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:56:03.074381Z","iopub.execute_input":"2023-04-23T10:56:03.075136Z","iopub.status.idle":"2023-04-23T10:56:05.316805Z","shell.execute_reply.started":"2023-04-23T10:56:03.075093Z","shell.execute_reply":"2023-04-23T10:56:05.315678Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'grid',\n    \n    'metric' : {\n        'name': 'val_loss',\n        'goal': 'minimize'\n    },\n    \n    'parameters' : {\n        'model' : {\n            'values': ['NetDiffConv6_1', 'NetDiffConv6_2', 'NetDiffConv6_3']\n                  }\n    }\n    \n    }\n\npprint.pprint(sweep_config)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:56:06.654165Z","iopub.execute_input":"2023-04-23T10:56:06.654546Z","iopub.status.idle":"2023-04-23T10:56:06.661683Z","shell.execute_reply.started":"2023-04-23T10:56:06.654509Z","shell.execute_reply":"2023-04-23T10:56:06.660492Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"{'method': 'grid',\n 'metric': {'goal': 'minimize', 'name': 'val_loss'},\n 'parameters': {'model': {'values': ['NetDiffConv6_1',\n                                     'NetDiffConv6_2',\n                                     'NetDiffConv6_3']}}}\n","output_type":"stream"}]},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep_config, project=\"DiffConv6_Cifar10_Test_0\")","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:56:09.034654Z","iopub.execute_input":"2023-04-23T10:56:09.035777Z","iopub.status.idle":"2023-04-23T10:56:09.421025Z","shell.execute_reply.started":"2023-04-23T10:56:09.035730Z","shell.execute_reply":"2023-04-23T10:56:09.419868Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Create sweep with ID: 6cc4lpqk\nSweep URL: https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/sweeps/6cc4lpqk\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <center> TRAINING ++ </center>","metadata":{}},{"cell_type":"code","source":"# Train loop\ndef train(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for inputs, targets in tqdm(dataloader, desc='Training', leave=False):\n        inputs, targets = inputs.to(device), targets.to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        # compute statistics\n        running_loss += loss.item() * inputs.size(0)\n        predicted = outputs.argmax(dim=1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n\n# Test loop\ndef test(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, targets in tqdm(dataloader, desc='Testing', leave=False):\n            inputs, targets = inputs.to(device), targets.to(device)\n\n            # forward\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n            # compute statistics\n            running_loss += loss.item() * inputs.size(0)\n            predicted = outputs.argmax(dim=1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:56:12.361091Z","iopub.execute_input":"2023-04-23T10:56:12.361712Z","iopub.status.idle":"2023-04-23T10:56:12.373358Z","shell.execute_reply.started":"2023-04-23T10:56:12.361673Z","shell.execute_reply":"2023-04-23T10:56:12.372196Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nlearning_rate = 0.0001\nnum_epochs = 50\n# optimizer = 'Adam'\nlr_step_size = 10\nlr_gamma = 0.1\nbetas = (0.85, 0.999)\namsgrad = True","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:56:13.468920Z","iopub.execute_input":"2023-04-23T10:56:13.469856Z","iopub.status.idle":"2023-04-23T10:56:13.475520Z","shell.execute_reply.started":"2023-04-23T10:56:13.469803Z","shell.execute_reply":"2023-04-23T10:56:13.474409Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def main(config = None):\n    \n    # Define data loaders\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n\n    # Train and evaluate models\n    with wandb.init(config = config):\n        config = wandb.config\n        model_name = config.model\n\n        if config.model == 'NetDiffConv6_1':\n            model = NetDiffConv6_1().to(device)\n        elif config.model == 'NetDiffConv6_2':\n            model = NetDiffConv6_2().to(device)\n        elif config.model == 'NetDiffConv6_3':\n            model = NetDiffConv6_3().to(device)\n\n        print(f'Training {model_name} model...')\n\n        optimizer = optim.Adam(model.parameters(),\n                               lr=learning_rate,\n                               betas = betas,\n                               amsgrad = amsgrad,\n                              )\n\n    # LEARNING RATE SCHEDULERS\n    #     scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=num_epochs//3, T_mult=2, eta_min=0)\n\n        criterion = nn.CrossEntropyLoss()\n        best_val_acc = 0.0\n        for epoch in range(1, num_epochs+1):\n            scheduler.step()\n            train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n            val_loss, val_acc = test(model, test_loader, criterion, device)\n            print(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n\n            # log results to weights and biases\n            wandb.log({'train_loss': train_loss,\n                       'train_acc': train_acc,\n                       'val_loss': val_loss,\n                       'val_acc': val_acc})\n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                torch.save(model.state_dict(), f'{model_name}.pt')\n        print(f'{model_name} model finished training with best validation accuracy of {best_val_acc:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:56:14.432046Z","iopub.execute_input":"2023-04-23T10:56:14.432769Z","iopub.status.idle":"2023-04-23T10:56:14.444475Z","shell.execute_reply.started":"2023-04-23T10:56:14.432732Z","shell.execute_reply":"2023-04-23T10:56:14.443301Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"wandb.agent(sweep_id, main, count=3)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:56:16.013690Z","iopub.execute_input":"2023-04-23T10:56:16.014874Z","iopub.status.idle":"2023-04-23T14:28:26.454639Z","shell.execute_reply.started":"2023-04-23T10:56:16.014824Z","shell.execute_reply":"2023-04-23T14:28:26.453650Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lm3xjauv with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: NetDiffConv6_1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230423_105618-lm3xjauv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/lm3xjauv' target=\"_blank\">charmed-sweep-1</a></strong> to <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/sweeps/6cc4lpqk' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/sweeps/6cc4lpqk</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/sweeps/6cc4lpqk' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/sweeps/6cc4lpqk</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/lm3xjauv' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/lm3xjauv</a>"},"metadata":{}},{"name":"stdout","text":"Training NetDiffConv6_1 model...\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50, Train Loss: 1.4305, Train Acc: 0.4758, Val Loss: 1.0155, Val Acc: 0.6334\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/50, Train Loss: 1.0696, Train Acc: 0.6191, Val Loss: 0.7998, Val Acc: 0.7142\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/50, Train Loss: 0.9395, Train Acc: 0.6650, Val Loss: 0.7757, Val Acc: 0.7310\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/50, Train Loss: 0.8595, Train Acc: 0.6974, Val Loss: 0.6901, Val Acc: 0.7535\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/50, Train Loss: 0.8034, Train Acc: 0.7171, Val Loss: 0.6552, Val Acc: 0.7667\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/50, Train Loss: 0.7496, Train Acc: 0.7355, Val Loss: 0.6304, Val Acc: 0.7830\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/50, Train Loss: 0.7129, Train Acc: 0.7507, Val Loss: 0.5943, Val Acc: 0.7950\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/50, Train Loss: 0.6764, Train Acc: 0.7622, Val Loss: 0.5794, Val Acc: 0.7946\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/50, Train Loss: 0.6459, Train Acc: 0.7727, Val Loss: 0.5460, Val Acc: 0.8054\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/50, Train Loss: 0.6179, Train Acc: 0.7836, Val Loss: 0.5345, Val Acc: 0.8128\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/50, Train Loss: 0.5950, Train Acc: 0.7922, Val Loss: 0.5405, Val Acc: 0.8095\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/50, Train Loss: 0.5733, Train Acc: 0.7998, Val Loss: 0.5075, Val Acc: 0.8214\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/50, Train Loss: 0.5607, Train Acc: 0.8021, Val Loss: 0.5065, Val Acc: 0.8219\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/50, Train Loss: 0.5492, Train Acc: 0.8085, Val Loss: 0.4936, Val Acc: 0.8270\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/50, Train Loss: 0.5458, Train Acc: 0.8086, Val Loss: 0.4960, Val Acc: 0.8235\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/50, Train Loss: 0.6649, Train Acc: 0.7672, Val Loss: 0.6170, Val Acc: 0.7858\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/50, Train Loss: 0.6522, Train Acc: 0.7728, Val Loss: 0.5470, Val Acc: 0.8067\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/50, Train Loss: 0.6288, Train Acc: 0.7793, Val Loss: 0.5462, Val Acc: 0.8097\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/50, Train Loss: 0.6130, Train Acc: 0.7849, Val Loss: 0.5233, Val Acc: 0.8200\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/50, Train Loss: 0.5972, Train Acc: 0.7915, Val Loss: 0.5102, Val Acc: 0.8246\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21/50, Train Loss: 0.5748, Train Acc: 0.7985, Val Loss: 0.5244, Val Acc: 0.8219\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22/50, Train Loss: 0.5674, Train Acc: 0.8009, Val Loss: 0.4950, Val Acc: 0.8270\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23/50, Train Loss: 0.5498, Train Acc: 0.8077, Val Loss: 0.4685, Val Acc: 0.8381\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24/50, Train Loss: 0.5330, Train Acc: 0.8133, Val Loss: 0.4858, Val Acc: 0.8319\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25/50, Train Loss: 0.5200, Train Acc: 0.8181, Val Loss: 0.4612, Val Acc: 0.8427\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26/50, Train Loss: 0.5083, Train Acc: 0.8213, Val Loss: 0.4550, Val Acc: 0.8444\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27/50, Train Loss: 0.4963, Train Acc: 0.8264, Val Loss: 0.4523, Val Acc: 0.8421\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28/50, Train Loss: 0.4858, Train Acc: 0.8294, Val Loss: 0.4535, Val Acc: 0.8469\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29/50, Train Loss: 0.4709, Train Acc: 0.8339, Val Loss: 0.4332, Val Acc: 0.8518\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30/50, Train Loss: 0.4620, Train Acc: 0.8366, Val Loss: 0.4310, Val Acc: 0.8551\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 31/50, Train Loss: 0.4472, Train Acc: 0.8430, Val Loss: 0.4196, Val Acc: 0.8547\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 32/50, Train Loss: 0.4362, Train Acc: 0.8486, Val Loss: 0.4341, Val Acc: 0.8522\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 33/50, Train Loss: 0.4289, Train Acc: 0.8488, Val Loss: 0.4296, Val Acc: 0.8549\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 34/50, Train Loss: 0.4192, Train Acc: 0.8520, Val Loss: 0.4049, Val Acc: 0.8613\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 35/50, Train Loss: 0.4025, Train Acc: 0.8576, Val Loss: 0.4042, Val Acc: 0.8625\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 36/50, Train Loss: 0.3933, Train Acc: 0.8608, Val Loss: 0.3997, Val Acc: 0.8663\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 37/50, Train Loss: 0.3890, Train Acc: 0.8647, Val Loss: 0.4033, Val Acc: 0.8612\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 38/50, Train Loss: 0.3794, Train Acc: 0.8657, Val Loss: 0.3979, Val Acc: 0.8645\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 39/50, Train Loss: 0.3774, Train Acc: 0.8665, Val Loss: 0.3928, Val Acc: 0.8678\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 40/50, Train Loss: 0.3617, Train Acc: 0.8729, Val Loss: 0.3914, Val Acc: 0.8711\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 41/50, Train Loss: 0.3636, Train Acc: 0.8729, Val Loss: 0.3893, Val Acc: 0.8703\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 42/50, Train Loss: 0.3540, Train Acc: 0.8761, Val Loss: 0.3868, Val Acc: 0.8690\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 43/50, Train Loss: 0.3452, Train Acc: 0.8783, Val Loss: 0.3876, Val Acc: 0.8694\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 44/50, Train Loss: 0.3505, Train Acc: 0.8766, Val Loss: 0.3850, Val Acc: 0.8715\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 45/50, Train Loss: 0.3401, Train Acc: 0.8804, Val Loss: 0.3844, Val Acc: 0.8716\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 46/50, Train Loss: 0.3406, Train Acc: 0.8805, Val Loss: 0.3847, Val Acc: 0.8721\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 47/50, Train Loss: 0.3435, Train Acc: 0.8783, Val Loss: 0.3848, Val Acc: 0.8725\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 48/50, Train Loss: 0.4587, Train Acc: 0.8386, Val Loss: 0.4354, Val Acc: 0.8511\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 49/50, Train Loss: 0.4552, Train Acc: 0.8391, Val Loss: 0.4268, Val Acc: 0.8531\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 50/50, Train Loss: 0.4444, Train Acc: 0.8442, Val Loss: 0.4464, Val Acc: 0.8495\nNetDiffConv6_1 model finished training with best validation accuracy of 0.8725\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.095 MB of 0.095 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"992fb02caf4240bc8b8011f9ee79b849"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████▇▇</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂</td></tr><tr><td>val_acc</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████▇▇</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▄▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.84416</td></tr><tr><td>train_loss</td><td>0.44443</td></tr><tr><td>val_acc</td><td>0.8495</td></tr><tr><td>val_loss</td><td>0.44639</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">charmed-sweep-1</strong> at: <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/lm3xjauv' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/lm3xjauv</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230423_105618-lm3xjauv/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w4bhkj7k with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: NetDiffConv6_2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230423_120758-w4bhkj7k</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/w4bhkj7k' target=\"_blank\">rosy-sweep-2</a></strong> to <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/sweeps/6cc4lpqk' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/sweeps/6cc4lpqk</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/sweeps/6cc4lpqk' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/sweeps/6cc4lpqk</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/w4bhkj7k' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/w4bhkj7k</a>"},"metadata":{}},{"name":"stdout","text":"Training NetDiffConv6_2 model...\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50, Train Loss: 1.4230, Train Acc: 0.4788, Val Loss: 0.9831, Val Acc: 0.6435\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/50, Train Loss: 1.0667, Train Acc: 0.6172, Val Loss: 0.8205, Val Acc: 0.7086\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/50, Train Loss: 0.9324, Train Acc: 0.6682, Val Loss: 0.7490, Val Acc: 0.7345\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/50, Train Loss: 0.8613, Train Acc: 0.6944, Val Loss: 0.6763, Val Acc: 0.7617\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/50, Train Loss: 0.7933, Train Acc: 0.7195, Val Loss: 0.6731, Val Acc: 0.7639\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/50, Train Loss: 0.7530, Train Acc: 0.7336, Val Loss: 0.6271, Val Acc: 0.7857\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/50, Train Loss: 0.7064, Train Acc: 0.7520, Val Loss: 0.5945, Val Acc: 0.7901\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/50, Train Loss: 0.6765, Train Acc: 0.7612, Val Loss: 0.5756, Val Acc: 0.7993\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/50, Train Loss: 0.6404, Train Acc: 0.7728, Val Loss: 0.5503, Val Acc: 0.8107\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/50, Train Loss: 0.6150, Train Acc: 0.7830, Val Loss: 0.5375, Val Acc: 0.8141\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/50, Train Loss: 0.5892, Train Acc: 0.7911, Val Loss: 0.5222, Val Acc: 0.8194\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/50, Train Loss: 0.5719, Train Acc: 0.7994, Val Loss: 0.5069, Val Acc: 0.8271\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/50, Train Loss: 0.5595, Train Acc: 0.8038, Val Loss: 0.5005, Val Acc: 0.8268\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/50, Train Loss: 0.5491, Train Acc: 0.8090, Val Loss: 0.4958, Val Acc: 0.8280\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/50, Train Loss: 0.5445, Train Acc: 0.8089, Val Loss: 0.4974, Val Acc: 0.8283\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/50, Train Loss: 0.6679, Train Acc: 0.7662, Val Loss: 0.5526, Val Acc: 0.8078\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/50, Train Loss: 0.6510, Train Acc: 0.7718, Val Loss: 0.5401, Val Acc: 0.8099\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/50, Train Loss: 0.6296, Train Acc: 0.7815, Val Loss: 0.5316, Val Acc: 0.8151\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/50, Train Loss: 0.6076, Train Acc: 0.7876, Val Loss: 0.5672, Val Acc: 0.8062\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/50, Train Loss: 0.5912, Train Acc: 0.7932, Val Loss: 0.5177, Val Acc: 0.8198\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21/50, Train Loss: 0.5818, Train Acc: 0.7949, Val Loss: 0.4897, Val Acc: 0.8293\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22/50, Train Loss: 0.5587, Train Acc: 0.8048, Val Loss: 0.4958, Val Acc: 0.8324\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23/50, Train Loss: 0.5477, Train Acc: 0.8065, Val Loss: 0.5111, Val Acc: 0.8234\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24/50, Train Loss: 0.5346, Train Acc: 0.8113, Val Loss: 0.4681, Val Acc: 0.8380\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25/50, Train Loss: 0.5172, Train Acc: 0.8191, Val Loss: 0.4613, Val Acc: 0.8449\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26/50, Train Loss: 0.5070, Train Acc: 0.8227, Val Loss: 0.4420, Val Acc: 0.8484\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27/50, Train Loss: 0.4966, Train Acc: 0.8258, Val Loss: 0.4577, Val Acc: 0.8442\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28/50, Train Loss: 0.4771, Train Acc: 0.8320, Val Loss: 0.4501, Val Acc: 0.8450\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29/50, Train Loss: 0.4680, Train Acc: 0.8349, Val Loss: 0.4540, Val Acc: 0.8472\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30/50, Train Loss: 0.4542, Train Acc: 0.8407, Val Loss: 0.4231, Val Acc: 0.8577\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 31/50, Train Loss: 0.4419, Train Acc: 0.8446, Val Loss: 0.4452, Val Acc: 0.8556\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 32/50, Train Loss: 0.4344, Train Acc: 0.8481, Val Loss: 0.4332, Val Acc: 0.8554\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 33/50, Train Loss: 0.4242, Train Acc: 0.8506, Val Loss: 0.4252, Val Acc: 0.8570\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 34/50, Train Loss: 0.4136, Train Acc: 0.8563, Val Loss: 0.4114, Val Acc: 0.8607\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 35/50, Train Loss: 0.4016, Train Acc: 0.8601, Val Loss: 0.4128, Val Acc: 0.8615\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 36/50, Train Loss: 0.3935, Train Acc: 0.8621, Val Loss: 0.4118, Val Acc: 0.8639\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 37/50, Train Loss: 0.3902, Train Acc: 0.8626, Val Loss: 0.3983, Val Acc: 0.8670\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 38/50, Train Loss: 0.3784, Train Acc: 0.8675, Val Loss: 0.4074, Val Acc: 0.8666\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 39/50, Train Loss: 0.3728, Train Acc: 0.8686, Val Loss: 0.4048, Val Acc: 0.8669\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 40/50, Train Loss: 0.3665, Train Acc: 0.8695, Val Loss: 0.3951, Val Acc: 0.8686\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 41/50, Train Loss: 0.3595, Train Acc: 0.8738, Val Loss: 0.3918, Val Acc: 0.8689\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 42/50, Train Loss: 0.3554, Train Acc: 0.8746, Val Loss: 0.3873, Val Acc: 0.8713\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 43/50, Train Loss: 0.3518, Train Acc: 0.8754, Val Loss: 0.3867, Val Acc: 0.8716\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 44/50, Train Loss: 0.3453, Train Acc: 0.8787, Val Loss: 0.3876, Val Acc: 0.8721\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 45/50, Train Loss: 0.3473, Train Acc: 0.8789, Val Loss: 0.3897, Val Acc: 0.8703\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 46/50, Train Loss: 0.3404, Train Acc: 0.8795, Val Loss: 0.3860, Val Acc: 0.8714\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 47/50, Train Loss: 0.3398, Train Acc: 0.8789, Val Loss: 0.3864, Val Acc: 0.8704\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 48/50, Train Loss: 0.4540, Train Acc: 0.8395, Val Loss: 0.4433, Val Acc: 0.8517\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 49/50, Train Loss: 0.4563, Train Acc: 0.8397, Val Loss: 0.4440, Val Acc: 0.8520\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 50/50, Train Loss: 0.4440, Train Acc: 0.8447, Val Loss: 0.4368, Val Acc: 0.8564\nNetDiffConv6_2 model finished training with best validation accuracy of 0.8721\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.113 MB of 0.113 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dedaffba38c4e8ab740700d5fe4904b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████▇▇</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂</td></tr><tr><td>val_acc</td><td>▁▃▄▅▅▅▆▆▆▇▇▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████▇█</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.84472</td></tr><tr><td>train_loss</td><td>0.44403</td></tr><tr><td>val_acc</td><td>0.8564</td></tr><tr><td>val_loss</td><td>0.43683</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rosy-sweep-2</strong> at: <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/w4bhkj7k' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/w4bhkj7k</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230423_120758-w4bhkj7k/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l57mwy52 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: NetDiffConv6_3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230423_131800-l57mwy52</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/l57mwy52' target=\"_blank\">solar-sweep-3</a></strong> to <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/sweeps/6cc4lpqk' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/sweeps/6cc4lpqk</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/sweeps/6cc4lpqk' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/sweeps/6cc4lpqk</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/l57mwy52' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/l57mwy52</a>"},"metadata":{}},{"name":"stdout","text":"Training NetDiffConv6_3 model...\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50, Train Loss: 1.6263, Train Acc: 0.3983, Val Loss: 2.3615, Val Acc: 0.3313\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/50, Train Loss: 1.2631, Train Acc: 0.5427, Val Loss: 1.3789, Val Acc: 0.5302\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/50, Train Loss: 1.1011, Train Acc: 0.6078, Val Loss: 3.6813, Val Acc: 0.1880\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/50, Train Loss: 0.9922, Train Acc: 0.6461, Val Loss: 2.1379, Val Acc: 0.3972\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/50, Train Loss: 0.9262, Train Acc: 0.6717, Val Loss: 2.0419, Val Acc: 0.3733\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/50, Train Loss: 0.8696, Train Acc: 0.6931, Val Loss: 1.0976, Val Acc: 0.5963\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/50, Train Loss: 0.8268, Train Acc: 0.7072, Val Loss: 2.5608, Val Acc: 0.3871\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/50, Train Loss: 0.7868, Train Acc: 0.7234, Val Loss: 4.1529, Val Acc: 0.2348\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/50, Train Loss: 0.7610, Train Acc: 0.7290, Val Loss: 0.9058, Val Acc: 0.6907\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/50, Train Loss: 0.7276, Train Acc: 0.7450, Val Loss: 0.8825, Val Acc: 0.7114\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/50, Train Loss: 0.7066, Train Acc: 0.7504, Val Loss: 0.8997, Val Acc: 0.6967\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/50, Train Loss: 0.6807, Train Acc: 0.7594, Val Loss: 0.7084, Val Acc: 0.7497\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/50, Train Loss: 0.6698, Train Acc: 0.7641, Val Loss: 0.6090, Val Acc: 0.7896\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/50, Train Loss: 0.6581, Train Acc: 0.7696, Val Loss: 0.5561, Val Acc: 0.8086\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/50, Train Loss: 0.6553, Train Acc: 0.7690, Val Loss: 0.5548, Val Acc: 0.8098\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/50, Train Loss: 0.7720, Train Acc: 0.7276, Val Loss: 1.5014, Val Acc: 0.5312\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/50, Train Loss: 0.7581, Train Acc: 0.7341, Val Loss: 3.1457, Val Acc: 0.3259\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/50, Train Loss: 0.7332, Train Acc: 0.7433, Val Loss: 1.0981, Val Acc: 0.6496\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/50, Train Loss: 0.7104, Train Acc: 0.7474, Val Loss: 2.3056, Val Acc: 0.4706\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/50, Train Loss: 0.6938, Train Acc: 0.7571, Val Loss: 1.3781, Val Acc: 0.5642\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21/50, Train Loss: 0.6785, Train Acc: 0.7648, Val Loss: 1.5684, Val Acc: 0.5340\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22/50, Train Loss: 0.6626, Train Acc: 0.7687, Val Loss: 0.8937, Val Acc: 0.7042\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23/50, Train Loss: 0.6417, Train Acc: 0.7741, Val Loss: 1.9711, Val Acc: 0.5076\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24/50, Train Loss: 0.6282, Train Acc: 0.7816, Val Loss: 2.1498, Val Acc: 0.4847\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25/50, Train Loss: 0.6129, Train Acc: 0.7843, Val Loss: 1.0729, Val Acc: 0.6800\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26/50, Train Loss: 0.6026, Train Acc: 0.7904, Val Loss: 0.8890, Val Acc: 0.7010\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27/50, Train Loss: 0.5856, Train Acc: 0.7966, Val Loss: 1.3240, Val Acc: 0.6037\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28/50, Train Loss: 0.5777, Train Acc: 0.7977, Val Loss: 0.7111, Val Acc: 0.7580\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29/50, Train Loss: 0.5623, Train Acc: 0.8024, Val Loss: 0.8207, Val Acc: 0.7214\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30/50, Train Loss: 0.5524, Train Acc: 0.8055, Val Loss: 0.8344, Val Acc: 0.7321\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 31/50, Train Loss: 0.5423, Train Acc: 0.8097, Val Loss: 0.9014, Val Acc: 0.7123\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 32/50, Train Loss: 0.5266, Train Acc: 0.8143, Val Loss: 0.8120, Val Acc: 0.7286\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 33/50, Train Loss: 0.5190, Train Acc: 0.8194, Val Loss: 0.6148, Val Acc: 0.7879\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 34/50, Train Loss: 0.5047, Train Acc: 0.8231, Val Loss: 0.7485, Val Acc: 0.7471\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 35/50, Train Loss: 0.4958, Train Acc: 0.8257, Val Loss: 0.5705, Val Acc: 0.8155\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 36/50, Train Loss: 0.4880, Train Acc: 0.8287, Val Loss: 0.5541, Val Acc: 0.8113\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 37/50, Train Loss: 0.4806, Train Acc: 0.8321, Val Loss: 0.6045, Val Acc: 0.8012\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 38/50, Train Loss: 0.4685, Train Acc: 0.8336, Val Loss: 0.5283, Val Acc: 0.8249\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 39/50, Train Loss: 0.4608, Train Acc: 0.8378, Val Loss: 0.5251, Val Acc: 0.8194\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 40/50, Train Loss: 0.4544, Train Acc: 0.8410, Val Loss: 0.4322, Val Acc: 0.8527\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 41/50, Train Loss: 0.4511, Train Acc: 0.8421, Val Loss: 0.4296, Val Acc: 0.8572\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 42/50, Train Loss: 0.4425, Train Acc: 0.8460, Val Loss: 0.4351, Val Acc: 0.8523\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 43/50, Train Loss: 0.4330, Train Acc: 0.8466, Val Loss: 0.4194, Val Acc: 0.8559\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 44/50, Train Loss: 0.4353, Train Acc: 0.8485, Val Loss: 0.4155, Val Acc: 0.8577\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 45/50, Train Loss: 0.4311, Train Acc: 0.8491, Val Loss: 0.4145, Val Acc: 0.8586\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 46/50, Train Loss: 0.4266, Train Acc: 0.8514, Val Loss: 0.4133, Val Acc: 0.8597\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 47/50, Train Loss: 0.4285, Train Acc: 0.8498, Val Loss: 0.4117, Val Acc: 0.8603\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 48/50, Train Loss: 0.5458, Train Acc: 0.8073, Val Loss: 1.0642, Val Acc: 0.6808\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 49/50, Train Loss: 0.5441, Train Acc: 0.8099, Val Loss: 2.6465, Val Acc: 0.4406\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 50/50, Train Loss: 0.5297, Train Acc: 0.8141, Val Loss: 0.6612, Val Acc: 0.7752\nNetDiffConv6_3 model finished training with best validation accuracy of 0.8603\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.131 MB of 0.131 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9695ccc1c2ce4ca5ba6fde53a4f9cd63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▃▄▅▆▆▆▆▆▇▇▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████▇▇</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂</td></tr><tr><td>val_acc</td><td>▂▅▁▃▅▃▁▆▆▇▇▇▅▂▆▄▅▆▄▄▆▅▇▇▆▇▇▇▇▇████████▆▇</td></tr><tr><td>val_loss</td><td>▅▃▇▄▂▅█▂▂▂▁▁▃▆▂▅▃▂▄▄▂▃▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.81414</td></tr><tr><td>train_loss</td><td>0.52969</td></tr><tr><td>val_acc</td><td>0.7752</td></tr><tr><td>val_loss</td><td>0.66115</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">solar-sweep-3</strong> at: <a href='https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/l57mwy52' target=\"_blank\">https://wandb.ai/shiwayz/DiffConv6_Cifar10_Test_0/runs/l57mwy52</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230423_131800-l57mwy52/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"# import time\n# import requests\n\n# while True:\n#     try:\n#         # Replace the URL with the Kaggle page you want to keep alive\n#         requests.get(\"https://www.kaggle.com/your-username/your-notebook\")\n#     except:\n#         pass\n    \n#     # Adjust the sleep time to your liking, but keep it under 40 minutes\n#     time.sleep(300) # 5 minutes","metadata":{},"execution_count":null,"outputs":[]}]}