{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> IMPORT MODULES </center> ","metadata":{}},{"cell_type":"code","source":"import torch\nimport pprint\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\n\nimport wandb\nfrom wandb.keras import WandbCallback\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-23T10:50:24.479885Z","iopub.execute_input":"2023-04-23T10:50:24.480317Z","iopub.status.idle":"2023-04-23T10:50:32.858068Z","shell.execute_reply.started":"2023-04-23T10:50:24.480279Z","shell.execute_reply":"2023-04-23T10:50:32.856953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center> DIFFERENTIAL CONVOLUTION </center>","metadata":{}},{"cell_type":"code","source":"# [-765 to 255]  --> [-255 to 85] --> [0 to 255]\nclass DiffConv6_1(nn.Module):\n\n    def __init__(self):\n        super(DiffConv6_1, self).__init__()\n\n    def forward(self, x):\n        sizeofin = x.size()\n        \n        ins = sizeofin[0]\n        n = sizeofin[1]\n        sx = sizeofin[2]\n        sy = sizeofin[3]  \n\n        self.output = torch.zeros(ins,n*6,sx,sy, device = x.device)\n        dmax = x.max()\n        dmin = x.min()\n        \n        for i in range(0,ins):\n\n\n            # ORIGINAL INPUT\n            oM = 0\n            oN = n\n            \n            self.output[i,oM:oN,0:sx,0:sy]= x[i].clone()\n            \n            # HORIZONTAL DIFFERENCE\n            oM = n\n            oN = 2*n\n\n            #area = self.output[i,oM:oN,0:sx-1,0:sy]\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(x[i,0:n,0:sx-1,0:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(-x[i,0:n,1:sx,0:sy])\n            \n            # VERTICAL DIFFERENCE\n            oM = 2*n\n            oN = 3*n\n\n            #area = ptr[oM:oN,0:sx,0:sy-1]\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(x[i,0:n,0:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(-x[i,0:n,0:sx,1:sy])\n            \n            # SOUTH EAST\n            oM = 3*n\n            oN = 4*n\n\n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            # SOUTH WEST\n            oM = 4*n\n            oN = 5*n\n           \n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            \n            # RIGHT - SOUTH EAST - BOTTOM\n            oM = 5*n\n            oN = 6*n\n           \n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n                        \n            # Scale: [-765 to 255]  --> [-255 to 85]\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = ( (self.output[i,oM:oN,0:sx-1,0:sy-1].clone().detach()) / 3 ).int()\n            \n\n        oM = n\n        oN = 6*n\n\n           \n        #self.signInputs = self.output.sign()\n        #self.signInputs[0:ins,0:n,:,:] = torch.ones(ins,n,sx,sy)\n        \n        #Inplace error came from the line below\n        #self.output[0:ins,oM:oN,:,:] = self.output[0:ins,oM:oN].abs()\n        self.output[0:ins,oM:oN,:,:] = torch.abs(self.output[0:ins,oM:oN].clone().detach())\n        \n        #self.output[0:ins,oM:oN,:,:] = torch.sqrt(self.output[0:ins,oM:oN] * self.output[0:ins,oM:oN].clone().detach())\n\n        #print(self.output)\n\n        return self.output","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:55:48.627503Z","iopub.execute_input":"2023-04-23T10:55:48.627959Z","iopub.status.idle":"2023-04-23T10:55:48.652259Z","shell.execute_reply.started":"2023-04-23T10:55:48.627917Z","shell.execute_reply":"2023-04-23T10:55:48.650843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# [-765 to 765]  --> [-255 to 255] --> [0 to 255]\n\nclass DiffConv6_2(nn.Module):\n\n    def __init__(self):\n        super(DiffConv6_2, self).__init__()\n\n    def forward(self, x):\n        sizeofin = x.size()\n        \n        ins = sizeofin[0]\n        n = sizeofin[1]\n        sx = sizeofin[2]\n        sy = sizeofin[3]  \n\n        self.output = torch.zeros(ins,n*6,sx,sy, device = x.device)\n        dmax = x.max()\n        dmin = x.min()\n        \n        for i in range(0,ins):\n\n\n            # ORIGINAL INPUT\n            oM = 0\n            oN = n\n            \n            self.output[i,oM:oN,0:sx,0:sy]= x[i].clone()\n            \n            # HORIZONTAL DIFFERENCE\n            oM = n\n            oN = 2*n\n\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(x[i,0:n,0:sx-1,0:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(-x[i,0:n,1:sx,0:sy])\n            \n            # VERTICAL DIFFERENCE\n            oM = 2*n\n            oN = 3*n\n\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(x[i,0:n,0:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(-x[i,0:n,0:sx,1:sy])\n            \n            # SOUTH EAST\n            oM = 3*n\n            oN = 4*n\n\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            # SOUTH WEST\n            oM = 4*n\n            oN = 5*n\n           \n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            \n            # RIGHT - SOUTH EAST - BOTTOM\n            oM = 5*n\n            oN = 6*n\n           \n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(3*x[i,0:n,0:sx-1,0:sy-1]) # current pixel * 3\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            # [-765 to 765]  --> [-255 to 255] --> [0 to 255]\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = ( (self.output[i,oM:oN,0:sx-1,0:sy-1].clone().detach()) / 3 ).int()\n            \n\n        oM = n\n        oN = 6*n\n\n           \n        #self.signInputs = self.output.sign()\n        #self.signInputs[0:ins,0:n,:,:] = torch.ones(ins,n,sx,sy)\n        \n        #Inplace error came from the line below\n        #self.output[0:ins,oM:oN,:,:] = self.output[0:ins,oM:oN].abs()\n        self.output[0:ins,oM:oN,:,:] = torch.abs(self.output[0:ins,oM:oN].clone().detach())\n        \n        #self.output[0:ins,oM:oN,:,:] = torch.sqrt(self.output[0:ins,oM:oN] * self.output[0:ins,oM:oN].clone().detach())\n\n        #print(self.output)\n\n        return self.output","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:55:49.628849Z","iopub.execute_input":"2023-04-23T10:55:49.629225Z","iopub.status.idle":"2023-04-23T10:55:49.652514Z","shell.execute_reply.started":"2023-04-23T10:55:49.629191Z","shell.execute_reply":"2023-04-23T10:55:49.651396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# [-765 to 255]  --> [-510 to 510] --> [-255 to 255] --> [0 to 255]\n\nclass DiffConv6_3(nn.Module):\n\n    def __init__(self):\n        super(DiffConv6_3, self).__init__()\n\n    def forward(self, x):\n        sizeofin = x.size()\n        \n        ins = sizeofin[0]\n        n = sizeofin[1]\n        sx = sizeofin[2]\n        sy = sizeofin[3]  \n\n        self.output = torch.zeros(ins,n*6,sx,sy, device = x.device)\n        dmax = x.max()\n        dmin = x.min()\n        \n        for i in range(0,ins):\n\n\n            # ORIGINAL INPUT\n            oM = 0\n            oN = n\n            \n            self.output[i,oM:oN,0:sx,0:sy]= x[i].clone()\n            \n            # HORIZONTAL DIFFERENCE\n            oM = n\n            oN = 2*n\n\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(x[i,0:n,0:sx-1,0:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(-x[i,0:n,1:sx,0:sy])\n            \n            # VERTICAL DIFFERENCE\n            oM = 2*n\n            oN = 3*n\n\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(x[i,0:n,0:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(-x[i,0:n,0:sx,1:sy])\n            \n            # SOUTH EAST\n            oM = 3*n\n            oN = 4*n\n\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            # SOUTH WEST\n            oM = 4*n\n            oN = 5*n\n           \n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            \n            # RIGHT - SOUTH EAST - BOTTOM\n            oM = 5*n\n            oN = 6*n\n           \n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1]) \n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            # [-765 to 255]  --> [-510 to 510] --> [0 to 255]\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = ( ((self.output[i,oM:oN,0:sx-1,0:sy-1].clone().detach()) + 255) / 2).int()\n            \n\n        oM = n\n        oN = 6*n\n\n           \n        #self.signInputs = self.output.sign()\n        #self.signInputs[0:ins,0:n,:,:] = torch.ones(ins,n,sx,sy)\n        \n        #Inplace error came from the line below\n        #self.output[0:ins,oM:oN,:,:] = self.output[0:ins,oM:oN].abs()\n        self.output[0:ins,oM:oN,:,:] = torch.abs(self.output[0:ins,oM:oN].clone().detach())\n        \n        #self.output[0:ins,oM:oN,:,:] = torch.sqrt(self.output[0:ins,oM:oN] * self.output[0:ins,oM:oN].clone().detach())\n\n        #print(self.output)\n\n        return self.output","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:55:50.617997Z","iopub.execute_input":"2023-04-23T10:55:50.619902Z","iopub.status.idle":"2023-04-23T10:55:50.641579Z","shell.execute_reply.started":"2023-04-23T10:55:50.619852Z","shell.execute_reply":"2023-04-23T10:55:50.640480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center> DATASET </center>","metadata":{}},{"cell_type":"code","source":"# Define transforms for data preprocessing\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n])\n\n# Load CIFAR10 dataset\ntrain_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntest_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:55:56.747232Z","iopub.execute_input":"2023-04-23T10:55:56.748112Z","iopub.status.idle":"2023-04-23T10:55:58.304134Z","shell.execute_reply.started":"2023-04-23T10:55:56.748076Z","shell.execute_reply":"2023-04-23T10:55:58.303000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center> Network Architectures </center>","metadata":{}},{"cell_type":"code","source":"multiplier = 4\n\n# CNN with DiffConv6_1\nclass NetDiffConv6_1(nn.Module):\n    def __init__(self):\n        super(NetDiffConv6_1, self).__init__()\n        \n        self.diff = DiffConv6_1()\n        \n        self.conv1 = nn.Conv2d(18, 16*multiplier, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(16*multiplier)\n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.conv2 = nn.Conv2d(16*multiplier, 32*multiplier, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(32*multiplier)\n        \n        self.conv3 = nn.Conv2d(32*multiplier, 64*multiplier, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(64*multiplier)\n        \n        self.fc1 = nn.Linear(64*multiplier * 4 * 4, 256*multiplier)\n        self.dropout1 = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(256*multiplier, 128*multiplier)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.fc3 = nn.Linear(128*multiplier, 10)\n        \n    def forward(self, x):\n        x = self.diff(x)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x) # 16x16\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x) # 8x8\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x) # 4x4\n\n        x = x.view(-1, 64*multiplier * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x\n\n\n# CNN with DiffConv6_2\nclass NetDiffConv6_2(nn.Module):\n    def __init__(self):\n        super(NetDiffConv6_2, self).__init__()\n        \n        self.diff = DiffConv6_2()\n        \n        self.conv1 = nn.Conv2d(18, 16*multiplier, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(16*multiplier)\n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.conv2 = nn.Conv2d(16*multiplier, 32*multiplier, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(32*multiplier)\n        \n        self.conv3 = nn.Conv2d(32*multiplier, 64*multiplier, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(64*multiplier)\n        \n        self.fc1 = nn.Linear(64*multiplier * 4 * 4, 256*multiplier)\n        self.dropout1 = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(256*multiplier, 128*multiplier)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.fc3 = nn.Linear(128*multiplier, 10)\n        \n    def forward(self, x):\n        x = self.diff(x)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x) # 16x16\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x) # 8x8\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x) # 4x4\n\n        x = x.view(-1, 64*multiplier * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x\n\n# CNN with DiffConv6_3\nclass NetDiffConv6_3(nn.Module):\n    def __init__(self):\n        super(NetDiffConv6_3, self).__init__()\n        \n        self.diff = DiffConv6_3()\n        \n        self.conv1 = nn.Conv2d(18, 16*multiplier, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(16*multiplier)\n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.conv2 = nn.Conv2d(16*multiplier, 32*multiplier, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(32*multiplier)\n        \n        self.conv3 = nn.Conv2d(32*multiplier, 64*multiplier, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(64*multiplier)\n        \n        self.fc1 = nn.Linear(64*multiplier * 4 * 4, 256*multiplier)\n        self.dropout1 = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(256*multiplier, 128*multiplier)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.fc3 = nn.Linear(128*multiplier, 10)\n        \n    def forward(self, x):\n        x = self.diff(x)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x) # 16x16\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x) # 8x8\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x) # 4x4\n\n        x = x.view(-1, 64*multiplier * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:55:59.479358Z","iopub.execute_input":"2023-04-23T10:55:59.479757Z","iopub.status.idle":"2023-04-23T10:55:59.505247Z","shell.execute_reply.started":"2023-04-23T10:55:59.479721Z","shell.execute_reply":"2023-04-23T10:55:59.504256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center> WandB Config </center>","metadata":{}},{"cell_type":"code","source":"# Set up Weights and Biases\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:56:03.074381Z","iopub.execute_input":"2023-04-23T10:56:03.075136Z","iopub.status.idle":"2023-04-23T10:56:05.316805Z","shell.execute_reply.started":"2023-04-23T10:56:03.075093Z","shell.execute_reply":"2023-04-23T10:56:05.315678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'grid',\n    \n    'metric' : {\n        'name': 'val_loss',\n        'goal': 'minimize'\n    },\n    \n    'parameters' : {\n        'model' : {\n            'values': ['NetDiffConv6_1', 'NetDiffConv6_2', 'NetDiffConv6_3']\n                  }\n    }\n    \n    }\n\npprint.pprint(sweep_config)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:56:06.654165Z","iopub.execute_input":"2023-04-23T10:56:06.654546Z","iopub.status.idle":"2023-04-23T10:56:06.661683Z","shell.execute_reply.started":"2023-04-23T10:56:06.654509Z","shell.execute_reply":"2023-04-23T10:56:06.660492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep_config, project=\"DiffConv6_Cifar10_Test_0\")","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:56:09.034654Z","iopub.execute_input":"2023-04-23T10:56:09.035777Z","iopub.status.idle":"2023-04-23T10:56:09.421025Z","shell.execute_reply.started":"2023-04-23T10:56:09.035730Z","shell.execute_reply":"2023-04-23T10:56:09.419868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center> TRAINING ++ </center>","metadata":{}},{"cell_type":"code","source":"# Train loop\ndef train(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for inputs, targets in tqdm(dataloader, desc='Training', leave=False):\n        inputs, targets = inputs.to(device), targets.to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        # compute statistics\n        running_loss += loss.item() * inputs.size(0)\n        predicted = outputs.argmax(dim=1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n\n# Test loop\ndef test(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, targets in tqdm(dataloader, desc='Testing', leave=False):\n            inputs, targets = inputs.to(device), targets.to(device)\n\n            # forward\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n            # compute statistics\n            running_loss += loss.item() * inputs.size(0)\n            predicted = outputs.argmax(dim=1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:56:12.361091Z","iopub.execute_input":"2023-04-23T10:56:12.361712Z","iopub.status.idle":"2023-04-23T10:56:12.373358Z","shell.execute_reply.started":"2023-04-23T10:56:12.361673Z","shell.execute_reply":"2023-04-23T10:56:12.372196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nlearning_rate = 0.0001\nnum_epochs = 50\n# optimizer = 'Adam'\nlr_step_size = 10\nlr_gamma = 0.1\nbetas = (0.85, 0.999)\namsgrad = True","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:56:13.468920Z","iopub.execute_input":"2023-04-23T10:56:13.469856Z","iopub.status.idle":"2023-04-23T10:56:13.475520Z","shell.execute_reply.started":"2023-04-23T10:56:13.469803Z","shell.execute_reply":"2023-04-23T10:56:13.474409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main(config = None):\n    \n    # Define data loaders\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n\n    # Train and evaluate models\n    with wandb.init(config = config):\n        config = wandb.config\n        model_name = config.model\n\n        if config.model == 'NetDiffConv6_1':\n            model = NetDiffConv6_1().to(device)\n        elif config.model == 'NetDiffConv6_2':\n            model = NetDiffConv6_2().to(device)\n        elif config.model == 'NetDiffConv6_3':\n            model = NetDiffConv6_3().to(device)\n\n        print(f'Training {model_name} model...')\n\n        optimizer = optim.Adam(model.parameters(),\n                               lr=learning_rate,\n                               betas = betas,\n                               amsgrad = amsgrad,\n                              )\n\n    # LEARNING RATE SCHEDULERS\n    #     scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=num_epochs//3, T_mult=2, eta_min=0)\n\n        criterion = nn.CrossEntropyLoss()\n        best_val_acc = 0.0\n        for epoch in range(1, num_epochs+1):\n            scheduler.step()\n            train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n            val_loss, val_acc = test(model, test_loader, criterion, device)\n            print(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n\n            # log results to weights and biases\n            wandb.log({'train_loss': train_loss,\n                       'train_acc': train_acc,\n                       'val_loss': val_loss,\n                       'val_acc': val_acc})\n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                torch.save(model.state_dict(), f'{model_name}.pt')\n        print(f'{model_name} model finished training with best validation accuracy of {best_val_acc:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:56:14.432046Z","iopub.execute_input":"2023-04-23T10:56:14.432769Z","iopub.status.idle":"2023-04-23T10:56:14.444475Z","shell.execute_reply.started":"2023-04-23T10:56:14.432732Z","shell.execute_reply":"2023-04-23T10:56:14.443301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.agent(sweep_id, main, count=3)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:56:16.013690Z","iopub.execute_input":"2023-04-23T10:56:16.014874Z","iopub.status.idle":"2023-04-23T14:28:26.454639Z","shell.execute_reply.started":"2023-04-23T10:56:16.014824Z","shell.execute_reply":"2023-04-23T14:28:26.453650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import time\n# import requests\n\n# while True:\n#     try:\n#         # Replace the URL with the Kaggle page you want to keep alive\n#         requests.get(\"https://www.kaggle.com/your-username/your-notebook\")\n#     except:\n#         pass\n    \n#     # Adjust the sleep time to your liking, but keep it under 40 minutes\n#     time.sleep(300) # 5 minutes","metadata":{},"execution_count":null,"outputs":[]}]}