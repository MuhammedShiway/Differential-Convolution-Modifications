{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\n\nimport wandb\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-21T08:47:51.968988Z","iopub.execute_input":"2023-04-21T08:47:51.969625Z","iopub.status.idle":"2023-04-21T08:47:52.868591Z","shell.execute_reply.started":"2023-04-21T08:47:51.969586Z","shell.execute_reply":"2023-04-21T08:47:52.867216Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class DiffConv4(nn.Module):\n\n    def __init__(self):\n        super(DiffConv4, self).__init__()\n\n    def forward(self, x):\n        sizeofin = x.size()\n                \n        ins = sizeofin[0]\n        n = sizeofin[1]\n        sx = sizeofin[2]\n        sy = sizeofin[3]  \n\n        self.output = torch.zeros(ins,n*4,sx,sy, device = x.device)\n\n        for i in range(0,ins):\n\n            # ORIGINAL INPUT\n            oM = 0\n            oN = n\n            \n            self.output[i,oM:oN,0:sx,0:sy]= x[i].clone()\n            \n            # HORIZONTAL DIFFERENCE\n            oM = n\n            oN = 2*n\n\n            #area = self.output[i,oM:oN,0:sx-1,0:sy]\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(x[i,0:n,0:sx-1,0:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(-x[i,0:n,1:sx,0:sy])\n            \n            # VERTICAL DIFFERENCE\n            oM = 2*n\n            oN = 3*n\n\n            #area = ptr[oM:oN,0:sx,0:sy-1]\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(x[i,0:n,0:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(-x[i,0:n,0:sx,1:sy])\n            \n            # SOUTH EAST\n            oM = 3*n\n            oN = 4*n\n\n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n#             # SOUTH WEST\n#             oM = 4*n\n#             oN = 5*n\n           \n#             #area = ptr[oM:oN,0:sx-1,0:sy-1]\n#             self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,1:sx,0:sy-1])\n#             self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            \n            \n\n        oM = n\n        oN = 4*n\n\n        \n        #Inplace error came from the line below\n        #self.output[0:ins,oM:oN,:,:] = self.output[0:ins,oM:oN].abs()\n        self.output[0:ins,oM:oN,:,:] = torch.abs(self.output[0:ins,oM:oN].clone().detach())\n        \n        #print(self.output)\n\n        return self.output\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T09:09:43.519515Z","iopub.execute_input":"2023-04-21T09:09:43.520525Z","iopub.status.idle":"2023-04-21T09:09:43.851660Z","shell.execute_reply.started":"2023-04-21T09:09:43.520483Z","shell.execute_reply":"2023-04-21T09:09:43.850588Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torch.nn as nn\nfrom torchvision import transforms, models\nfrom PIL import Image\n\nimport torch\nimport numpy as np\nimport torch.nn as nn\n\nclass DiffConv5(nn.Module):\n\n    def __init__(self):\n        super(DiffConv5, self).__init__()\n\n    def forward(self, x):\n        sizeofin = x.size()\n        \n        ins = sizeofin[0]\n        n = sizeofin[1]\n        sx = sizeofin[2]\n        sy = sizeofin[3]  \n\n        self.output = torch.zeros(ins,n*5,sx,sy, device = x.device)\n\n        for i in range(0,ins):\n\n\n            # ORIGINAL INPUT\n            oM = 0\n            oN = n\n            \n            self.output[i,oM:oN,0:sx,0:sy]= x[i].clone()\n            \n            # HORIZONTAL DIFFERENCE\n            oM = n\n            oN = 2*n\n\n            #area = self.output[i,oM:oN,0:sx-1,0:sy]\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(x[i,0:n,0:sx-1,0:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(-x[i,0:n,1:sx,0:sy])\n            \n            # VERTICAL DIFFERENCE\n            oM = 2*n\n            oN = 3*n\n\n            #area = ptr[oM:oN,0:sx,0:sy-1]\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(x[i,0:n,0:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(-x[i,0:n,0:sx,1:sy])\n            \n            # SOUTH EAST\n            oM = 3*n\n            oN = 4*n\n\n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            # SOUTH WEST\n            oM = 4*n\n            oN = 5*n\n           \n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            \n            \n\n        oM = n\n        oN = 5*n\n\n        \n        #Inplace error came from the line below\n        #self.output[0:ins,oM:oN,:,:] = self.output[0:ins,oM:oN].abs()\n        self.output[0:ins,oM:oN,:,:] = torch.abs(self.output[0:ins,oM:oN].clone().detach())\n        \n        #print(self.output)\n\n        return self.output\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T09:09:44.444282Z","iopub.execute_input":"2023-04-21T09:09:44.444761Z","iopub.status.idle":"2023-04-21T09:09:44.741646Z","shell.execute_reply.started":"2023-04-21T09:09:44.444715Z","shell.execute_reply":"2023-04-21T09:09:44.740386Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class DiffConv6(nn.Module):\n\n    def __init__(self):\n        super(DiffConv6, self).__init__()\n\n    def forward(self, x):\n        sizeofin = x.size()\n        \n        ins = sizeofin[0]\n        n = sizeofin[1]\n        sx = sizeofin[2]\n        sy = sizeofin[3]  \n\n        self.output = torch.zeros(ins,n*6,sx,sy, device = x.device)\n        dmax = x.max()\n        dmin = x.min()\n        \n        for i in range(0,ins):\n\n\n            # ORIGINAL INPUT\n            oM = 0\n            oN = n\n            \n            self.output[i,oM:oN,0:sx,0:sy]= x[i].clone()\n            \n            # HORIZONTAL DIFFERENCE\n            oM = n\n            oN = 2*n\n\n            #area = self.output[i,oM:oN,0:sx-1,0:sy]\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(x[i,0:n,0:sx-1,0:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(-x[i,0:n,1:sx,0:sy])\n            \n            # VERTICAL DIFFERENCE\n            oM = 2*n\n            oN = 3*n\n\n            #area = ptr[oM:oN,0:sx,0:sy-1]\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(x[i,0:n,0:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(-x[i,0:n,0:sx,1:sy])\n            \n            # SOUTH EAST\n            oM = 3*n\n            oN = 4*n\n\n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            # SOUTH WEST\n            oM = 4*n\n            oN = 5*n\n           \n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            \n            # RIGHT - SOUTH EAST - BOTTOM\n            oM = 5*n\n            oN = 6*n\n           \n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            #SCALE [-765 to 255] to [0 to 255]\n            \n            amin = self.output[i,oM:oN,0:sx-1,0:sy-1].clone().detach().min()\n            amax = self.output[i,oM:oN,0:sx-1,0:sy-1].clone().detach().max()\n            # Scale: -255 to 85\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = ( (self.output[i,oM:oN,0:sx-1,0:sy-1].clone().detach()) / 3 ).int()\n            \n\n        oM = n\n        oN = 6*n\n\n           \n        #self.signInputs = self.output.sign()\n        #self.signInputs[0:ins,0:n,:,:] = torch.ones(ins,n,sx,sy)\n        \n        #Inplace error came from the line below\n        #self.output[0:ins,oM:oN,:,:] = self.output[0:ins,oM:oN].abs()\n        self.output[0:ins,oM:oN,:,:] = torch.abs(self.output[0:ins,oM:oN].clone().detach())\n        \n        #self.output[0:ins,oM:oN,:,:] = torch.sqrt(self.output[0:ins,oM:oN] * self.output[0:ins,oM:oN].clone().detach())\n\n        #print(self.output)\n\n        return self.output","metadata":{"execution":{"iopub.status.busy":"2023-04-21T09:09:45.159957Z","iopub.execute_input":"2023-04-21T09:09:45.160310Z","iopub.status.idle":"2023-04-21T09:09:45.485347Z","shell.execute_reply.started":"2023-04-21T09:09:45.160279Z","shell.execute_reply":"2023-04-21T09:09:45.484133Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Set up Weights and Biases\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:48:21.665157Z","iopub.execute_input":"2023-04-21T08:48:21.665574Z","iopub.status.idle":"2023-04-21T08:48:27.890084Z","shell.execute_reply.started":"2023-04-21T08:48:21.665536Z","shell.execute_reply":"2023-04-21T08:48:27.888960Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"wandb.init(project=\"Diffconv_Cifar10\")","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:48:30.942436Z","iopub.execute_input":"2023-04-21T08:48:30.943561Z","iopub.status.idle":"2023-04-21T08:49:01.849759Z","shell.execute_reply.started":"2023-04-21T08:48:30.943504Z","shell.execute_reply":"2023-04-21T08:49:01.848653Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshiwayz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230421_084830-b5d6a8tp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shiwayz/Diffconv_Cifar10/runs/b5d6a8tp' target=\"_blank\">snowy-pyramid-4</a></strong> to <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10/runs/b5d6a8tp' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10/runs/b5d6a8tp</a>"},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/shiwayz/Diffconv_Cifar10/runs/b5d6a8tp?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7dc1602dc050>"},"metadata":{}}]},{"cell_type":"code","source":"# Define transforms for data preprocessing\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n])\n\n# Load CIFAR10 dataset\ntrain_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntest_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n\n# Define data loaders\nbatch_size = 128\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:49:01.855146Z","iopub.execute_input":"2023-04-21T08:49:01.858078Z","iopub.status.idle":"2023-04-21T08:49:11.888478Z","shell.execute_reply.started":"2023-04-21T08:49:01.858034Z","shell.execute_reply":"2023-04-21T08:49:11.887184Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/170498071 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d5f7c3a802e46d9a7dd6710dd1b211b"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"for batch_idx, (data, target) in enumerate(train_loader):\n    print(data.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:49:11.894665Z","iopub.execute_input":"2023-04-21T08:49:11.895253Z","iopub.status.idle":"2023-04-21T08:49:12.433680Z","shell.execute_reply.started":"2023-04-21T08:49:11.895220Z","shell.execute_reply":"2023-04-21T08:49:12.432590Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"torch.Size([128, 3, 32, 32])\n","output_type":"stream"}]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(64)\n        \n        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n        \n        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n        self.dropout1 = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(512, 256)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.fc3 = nn.Linear(256, 10)\n        \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x) # 16x16\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x) # 8x8\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x) # 4x4\n\n        x = x.view(-1, 128 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-04-21T09:12:52.899157Z","iopub.execute_input":"2023-04-21T09:12:52.900184Z","iopub.status.idle":"2023-04-21T09:12:53.218156Z","shell.execute_reply.started":"2023-04-21T09:12:52.900141Z","shell.execute_reply":"2023-04-21T09:12:53.216905Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# CNN with DiffConv4\nclass NetDiffConv4(nn.Module):\n    def __init__(self):\n        super(NetDiffConv4, self).__init__()\n        \n        self.diff = DiffConv4()\n        \n        self.conv1 = nn.Conv2d(12, 64, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(128)\n        \n        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(256)\n        \n        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n        self.dropout1 = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(512, 256)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.fc3 = nn.Linear(256, 10)\n        \n    def forward(self, x):\n        x = self.diff(x)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x) # 16x16\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x) # 8x8\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x) # 4x4\n\n        x = x.view(-1, 256 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x\n\n\n# CNN with DiffConv5\nclass NetDiffConv5(nn.Module):\n    def __init__(self):\n        super(NetDiffConv5, self).__init__()\n        self.diff = DiffConv5()\n        \n        self.conv1 = nn.Conv2d(15, 64, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(128)\n        \n        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(256)\n        \n        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n        self.dropout1 = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(512, 256)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.fc3 = nn.Linear(256, 10)\n        \n    def forward(self, x):\n        x = self.diff(x)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x) # 16x16\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x) # 8x8\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x) # 4x4\n\n        x = x.view(-1, 256 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x\n\n\n\n# CNN with DiffConv6\nclass NetDiffConv6(nn.Module):\n    def __init__(self):\n        super(NetDiffConv6, self).__init__()\n        self.diff = DiffConv6()\n\n        self.conv1 = nn.Conv2d(18, 64, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(128)\n        \n        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(256)\n        \n        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n        self.dropout1 = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(512, 256)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.fc3 = nn.Linear(256, 10)\n        \n    def forward(self, x):\n        x = self.diff(x)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x) # 16x16\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x) # 8x8\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x) # 4x4\n\n        x = x.view(-1, 256 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-04-21T09:09:51.212424Z","iopub.execute_input":"2023-04-21T09:09:51.212847Z","iopub.status.idle":"2023-04-21T09:09:51.490838Z","shell.execute_reply.started":"2023-04-21T09:09:51.212808Z","shell.execute_reply":"2023-04-21T09:09:51.489804Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Train loop\ndef train(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for inputs, targets in tqdm(dataloader, desc='Training', leave=False):\n        inputs, targets = inputs.to(device), targets.to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        # compute statistics\n        running_loss += loss.item() * inputs.size(0)\n        predicted = outputs.argmax(dim=1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n\n# Test loop\ndef test(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, targets in tqdm(dataloader, desc='Testing', leave=False):\n            inputs, targets = inputs.to(device), targets.to(device)\n\n            # forward\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n            # compute statistics\n            running_loss += loss.item() * inputs.size(0)\n            predicted = outputs.argmax(dim=1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T09:05:36.966802Z","iopub.execute_input":"2023-04-21T09:05:36.967711Z","iopub.status.idle":"2023-04-21T09:05:37.315111Z","shell.execute_reply.started":"2023-04-21T09:05:36.967669Z","shell.execute_reply":"2023-04-21T09:05:37.314052Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.001\nnum_epochs = 20\noptimizer = 'Adam'\nlr_step_size = 10\nlr_gamma = 0.1","metadata":{"execution":{"iopub.status.busy":"2023-04-21T09:12:06.557166Z","iopub.execute_input":"2023-04-21T09:12:06.558176Z","iopub.status.idle":"2023-04-21T09:12:06.819587Z","shell.execute_reply.started":"2023-04-21T09:12:06.558134Z","shell.execute_reply":"2023-04-21T09:12:06.818066Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"my_models = {\n          'CNN': CNN(),\n          'NetDiffConv4': NetDiffConv4(),\n          'NetDiffConv5': NetDiffConv5(),\n          'NetDiffConv6': NetDiffConv6(),\n}\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T09:12:57.711237Z","iopub.execute_input":"2023-04-21T09:12:57.711978Z","iopub.status.idle":"2023-04-21T09:12:58.095729Z","shell.execute_reply.started":"2023-04-21T09:12:57.711938Z","shell.execute_reply":"2023-04-21T09:12:58.094467Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Train and evaluate models\nfor model_name, model in my_models.items():\n    model.to(device)\n    print(f'Training {model_name} model...')\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n    criterion = nn.CrossEntropyLoss()\n    best_val_acc = 0.0\n    for epoch in range(1, num_epochs+1):\n        scheduler.step()\n        train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n        val_loss, val_acc = test(model, test_loader, criterion, device)\n        print(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n        # log results to weights and biases\n        wandb.log({f'{model_name}_train_loss': train_loss, f'{model_name}_train_acc': train_acc,\n                   f'{model_name}_val_loss': val_loss, f'{model_name}_val_acc': val_acc})\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), f'{model_name}.pt')\n    print(f'{model_name} model finished training with best validation accuracy of {best_val_acc:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T09:12:59.538790Z","iopub.execute_input":"2023-04-21T09:12:59.539200Z","iopub.status.idle":"2023-04-21T10:20:20.471740Z","shell.execute_reply.started":"2023-04-21T09:12:59.539163Z","shell.execute_reply":"2023-04-21T10:20:20.470414Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Training CNN model...\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20, Train Loss: 1.5638, Train Acc: 0.4200, Val Loss: 1.3256, Val Acc: 0.5304\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20, Train Loss: 1.2474, Train Acc: 0.5486, Val Loss: 1.1042, Val Acc: 0.6074\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20, Train Loss: 1.1117, Train Acc: 0.6010, Val Loss: 0.9234, Val Acc: 0.6704\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20, Train Loss: 1.0279, Train Acc: 0.6370, Val Loss: 0.8538, Val Acc: 0.7020\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20, Train Loss: 0.9601, Train Acc: 0.6620, Val Loss: 0.8284, Val Acc: 0.7032\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20, Train Loss: 0.9094, Train Acc: 0.6773, Val Loss: 0.7459, Val Acc: 0.7424\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20, Train Loss: 0.8744, Train Acc: 0.6915, Val Loss: 0.7274, Val Acc: 0.7433\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20, Train Loss: 0.8457, Train Acc: 0.7039, Val Loss: 0.6851, Val Acc: 0.7625\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20, Train Loss: 0.8106, Train Acc: 0.7146, Val Loss: 0.7012, Val Acc: 0.7563\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20, Train Loss: 0.7193, Train Acc: 0.7494, Val Loss: 0.6021, Val Acc: 0.7890\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20, Train Loss: 0.6907, Train Acc: 0.7574, Val Loss: 0.6066, Val Acc: 0.7891\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20, Train Loss: 0.6821, Train Acc: 0.7610, Val Loss: 0.5903, Val Acc: 0.7924\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20, Train Loss: 0.6786, Train Acc: 0.7611, Val Loss: 0.5870, Val Acc: 0.7941\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20, Train Loss: 0.6673, Train Acc: 0.7663, Val Loss: 0.5847, Val Acc: 0.7950\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20, Train Loss: 0.6622, Train Acc: 0.7666, Val Loss: 0.5791, Val Acc: 0.7951\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20, Train Loss: 0.6568, Train Acc: 0.7700, Val Loss: 0.5718, Val Acc: 0.7992\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20, Train Loss: 0.6550, Train Acc: 0.7704, Val Loss: 0.5738, Val Acc: 0.8024\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20, Train Loss: 0.6465, Train Acc: 0.7736, Val Loss: 0.5732, Val Acc: 0.7996\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20, Train Loss: 0.6427, Train Acc: 0.7746, Val Loss: 0.5620, Val Acc: 0.8057\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20, Train Loss: 0.6363, Train Acc: 0.7767, Val Loss: 0.5586, Val Acc: 0.8054\nCNN model finished training with best validation accuracy of 0.8057\nTraining NetDiffConv4 model...\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20, Train Loss: 1.5055, Train Acc: 0.4430, Val Loss: 1.1314, Val Acc: 0.5929\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20, Train Loss: 1.1380, Train Acc: 0.5902, Val Loss: 0.9831, Val Acc: 0.6542\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20, Train Loss: 1.0042, Train Acc: 0.6449, Val Loss: 0.8649, Val Acc: 0.6957\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20, Train Loss: 0.9159, Train Acc: 0.6754, Val Loss: 0.7356, Val Acc: 0.7400\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20, Train Loss: 0.8523, Train Acc: 0.7025, Val Loss: 0.7804, Val Acc: 0.7370\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20, Train Loss: 0.8027, Train Acc: 0.7191, Val Loss: 0.6738, Val Acc: 0.7627\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20, Train Loss: 0.7748, Train Acc: 0.7310, Val Loss: 0.6650, Val Acc: 0.7693\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20, Train Loss: 0.7249, Train Acc: 0.7486, Val Loss: 0.6351, Val Acc: 0.7840\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20, Train Loss: 0.7001, Train Acc: 0.7583, Val Loss: 0.6039, Val Acc: 0.7933\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20, Train Loss: 0.5994, Train Acc: 0.7923, Val Loss: 0.5155, Val Acc: 0.8210\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20, Train Loss: 0.5783, Train Acc: 0.7986, Val Loss: 0.5110, Val Acc: 0.8243\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20, Train Loss: 0.5636, Train Acc: 0.8032, Val Loss: 0.5061, Val Acc: 0.8257\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20, Train Loss: 0.5529, Train Acc: 0.8086, Val Loss: 0.4993, Val Acc: 0.8282\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20, Train Loss: 0.5471, Train Acc: 0.8080, Val Loss: 0.4923, Val Acc: 0.8308\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20, Train Loss: 0.5389, Train Acc: 0.8111, Val Loss: 0.4901, Val Acc: 0.8324\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20, Train Loss: 0.5330, Train Acc: 0.8139, Val Loss: 0.4846, Val Acc: 0.8331\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20, Train Loss: 0.5244, Train Acc: 0.8152, Val Loss: 0.4824, Val Acc: 0.8342\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20, Train Loss: 0.5213, Train Acc: 0.8180, Val Loss: 0.4822, Val Acc: 0.8356\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20, Train Loss: 0.5124, Train Acc: 0.8208, Val Loss: 0.4781, Val Acc: 0.8382\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20, Train Loss: 0.5066, Train Acc: 0.8223, Val Loss: 0.4701, Val Acc: 0.8416\nNetDiffConv4 model finished training with best validation accuracy of 0.8416\nTraining NetDiffConv5 model...\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20, Train Loss: 1.4941, Train Acc: 0.4507, Val Loss: 1.0852, Val Acc: 0.6112\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20, Train Loss: 1.1178, Train Acc: 0.5971, Val Loss: 0.8866, Val Acc: 0.6870\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20, Train Loss: 0.9808, Train Acc: 0.6529, Val Loss: 0.8274, Val Acc: 0.7083\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20, Train Loss: 0.8963, Train Acc: 0.6830, Val Loss: 0.8178, Val Acc: 0.7120\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20, Train Loss: 0.8364, Train Acc: 0.7061, Val Loss: 0.7428, Val Acc: 0.7409\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20, Train Loss: 0.7881, Train Acc: 0.7234, Val Loss: 0.6483, Val Acc: 0.7719\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20, Train Loss: 0.7554, Train Acc: 0.7380, Val Loss: 0.6299, Val Acc: 0.7822\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20, Train Loss: 0.7194, Train Acc: 0.7490, Val Loss: 0.6186, Val Acc: 0.7880\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20, Train Loss: 0.6955, Train Acc: 0.7599, Val Loss: 0.6228, Val Acc: 0.7870\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20, Train Loss: 0.5965, Train Acc: 0.7936, Val Loss: 0.5182, Val Acc: 0.8230\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20, Train Loss: 0.5667, Train Acc: 0.8032, Val Loss: 0.5003, Val Acc: 0.8275\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20, Train Loss: 0.5585, Train Acc: 0.8057, Val Loss: 0.5011, Val Acc: 0.8282\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20, Train Loss: 0.5515, Train Acc: 0.8094, Val Loss: 0.4910, Val Acc: 0.8325\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20, Train Loss: 0.5350, Train Acc: 0.8122, Val Loss: 0.4870, Val Acc: 0.8337\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20, Train Loss: 0.5322, Train Acc: 0.8147, Val Loss: 0.4831, Val Acc: 0.8340\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20, Train Loss: 0.5259, Train Acc: 0.8148, Val Loss: 0.4850, Val Acc: 0.8329\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20, Train Loss: 0.5213, Train Acc: 0.8174, Val Loss: 0.4835, Val Acc: 0.8319\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20, Train Loss: 0.5114, Train Acc: 0.8221, Val Loss: 0.4816, Val Acc: 0.8353\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20, Train Loss: 0.5106, Train Acc: 0.8215, Val Loss: 0.4693, Val Acc: 0.8364\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20, Train Loss: 0.5028, Train Acc: 0.8250, Val Loss: 0.4678, Val Acc: 0.8402\nNetDiffConv5 model finished training with best validation accuracy of 0.8402\nTraining NetDiffConv6 model...\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20, Train Loss: 1.5241, Train Acc: 0.4341, Val Loss: 1.2067, Val Acc: 0.5626\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20, Train Loss: 1.1413, Train Acc: 0.5894, Val Loss: 0.9049, Val Acc: 0.6779\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20, Train Loss: 0.9862, Train Acc: 0.6507, Val Loss: 0.7970, Val Acc: 0.7207\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20, Train Loss: 0.8961, Train Acc: 0.6868, Val Loss: 0.7152, Val Acc: 0.7524\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20, Train Loss: 0.8361, Train Acc: 0.7079, Val Loss: 0.7023, Val Acc: 0.7550\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20, Train Loss: 0.7862, Train Acc: 0.7265, Val Loss: 0.6516, Val Acc: 0.7694\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20, Train Loss: 0.7466, Train Acc: 0.7383, Val Loss: 0.6569, Val Acc: 0.7737\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20, Train Loss: 0.7162, Train Acc: 0.7533, Val Loss: 0.5891, Val Acc: 0.7975\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20, Train Loss: 0.6842, Train Acc: 0.7640, Val Loss: 0.6278, Val Acc: 0.7831\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20, Train Loss: 0.5872, Train Acc: 0.7956, Val Loss: 0.5100, Val Acc: 0.8222\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20, Train Loss: 0.5675, Train Acc: 0.8029, Val Loss: 0.5005, Val Acc: 0.8269\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20, Train Loss: 0.5513, Train Acc: 0.8065, Val Loss: 0.4935, Val Acc: 0.8311\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20, Train Loss: 0.5450, Train Acc: 0.8090, Val Loss: 0.4885, Val Acc: 0.8325\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20, Train Loss: 0.5384, Train Acc: 0.8099, Val Loss: 0.4878, Val Acc: 0.8355\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20, Train Loss: 0.5329, Train Acc: 0.8127, Val Loss: 0.4874, Val Acc: 0.8328\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20, Train Loss: 0.5260, Train Acc: 0.8156, Val Loss: 0.4803, Val Acc: 0.8356\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20, Train Loss: 0.5205, Train Acc: 0.8174, Val Loss: 0.4782, Val Acc: 0.8361\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20, Train Loss: 0.5150, Train Acc: 0.8187, Val Loss: 0.4734, Val Acc: 0.8386\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20, Train Loss: 0.5085, Train Acc: 0.8231, Val Loss: 0.4736, Val Acc: 0.8371\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20, Train Loss: 0.4943, Train Acc: 0.8250, Val Loss: 0.4673, Val Acc: 0.8391\nNetDiffConv6 model finished training with best validation accuracy of 0.8391\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-04-21T04:11:37.942425Z","iopub.execute_input":"2023-04-21T04:11:37.945260Z","iopub.status.idle":"2023-04-21T04:11:38.518635Z","shell.execute_reply.started":"2023-04-21T04:11:37.945192Z","shell.execute_reply":"2023-04-21T04:11:38.517529Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"y = DiffConv4()(x)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T04:13:58.632438Z","iopub.execute_input":"2023-04-21T04:13:58.632925Z","iopub.status.idle":"2023-04-21T04:13:59.532256Z","shell.execute_reply.started":"2023-04-21T04:13:58.632845Z","shell.execute_reply":"2023-04-21T04:13:59.531148Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-21T04:14:04.811407Z","iopub.execute_input":"2023-04-21T04:14:04.811834Z","iopub.status.idle":"2023-04-21T04:14:05.624751Z","shell.execute_reply.started":"2023-04-21T04:14:04.811801Z","shell.execute_reply":"2023-04-21T04:14:05.623672Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 12, 10, 10])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}