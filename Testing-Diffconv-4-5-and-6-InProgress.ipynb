{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> IMPORT MODULES </center> ","metadata":{}},{"cell_type":"code","source":"pip install torch-summary","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:47:24.502756Z","iopub.execute_input":"2023-04-22T10:47:24.503254Z","iopub.status.idle":"2023-04-22T10:47:36.215217Z","shell.execute_reply.started":"2023-04-22T10:47:24.503206Z","shell.execute_reply":"2023-04-22T10:47:36.213841Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torch-summary\n  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\nInstalling collected packages: torch-summary\nSuccessfully installed torch-summary-1.4.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport pprint\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchsummary import summary\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\n\nimport wandb\nfrom wandb.keras import WandbCallback\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-22T10:47:36.217882Z","iopub.execute_input":"2023-04-22T10:47:36.218243Z","iopub.status.idle":"2023-04-22T10:47:44.230375Z","shell.execute_reply.started":"2023-04-22T10:47:36.218202Z","shell.execute_reply":"2023-04-22T10:47:44.229200Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# <center> DIFFERENTIAL CONVOLUTION </center>","metadata":{}},{"cell_type":"code","source":"class DiffConv4(nn.Module):\n\n    def __init__(self):\n        super(DiffConv4, self).__init__()\n\n    def forward(self, x):\n        sizeofin = x.size()\n                \n        ins = sizeofin[0]\n        n = sizeofin[1]\n        sx = sizeofin[2]\n        sy = sizeofin[3]  \n\n        self.output = torch.zeros(ins,n*4,sx,sy, device = x.device)\n\n        for i in range(0,ins):\n\n            # ORIGINAL INPUT\n            oM = 0\n            oN = n\n            \n            self.output[i,oM:oN,0:sx,0:sy]= x[i].clone()\n            \n            # HORIZONTAL DIFFERENCE\n            oM = n\n            oN = 2*n\n\n            #area = self.output[i,oM:oN,0:sx-1,0:sy]\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(x[i,0:n,0:sx-1,0:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(-x[i,0:n,1:sx,0:sy])\n            \n            # VERTICAL DIFFERENCE\n            oM = 2*n\n            oN = 3*n\n\n            #area = ptr[oM:oN,0:sx,0:sy-1]\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(x[i,0:n,0:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(-x[i,0:n,0:sx,1:sy])\n            \n            # SOUTH EAST\n            oM = 3*n\n            oN = 4*n\n\n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n#             # SOUTH WEST\n#             oM = 4*n\n#             oN = 5*n\n           \n#             #area = ptr[oM:oN,0:sx-1,0:sy-1]\n#             self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,1:sx,0:sy-1])\n#             self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            \n            \n\n        oM = n\n        oN = 4*n\n\n        \n        #Inplace error came from the line below\n        #self.output[0:ins,oM:oN,:,:] = self.output[0:ins,oM:oN].abs()\n        self.output[0:ins,oM:oN,:,:] = torch.abs(self.output[0:ins,oM:oN].clone().detach())\n        \n        #print(self.output)\n\n        return self.output\n","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:47:47.691429Z","iopub.execute_input":"2023-04-22T10:47:47.692179Z","iopub.status.idle":"2023-04-22T10:47:47.709592Z","shell.execute_reply.started":"2023-04-22T10:47:47.692140Z","shell.execute_reply":"2023-04-22T10:47:47.708140Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class DiffConv5(nn.Module):\n\n    def __init__(self):\n        super(DiffConv5, self).__init__()\n\n    def forward(self, x):\n        sizeofin = x.size()\n        \n        ins = sizeofin[0]\n        n = sizeofin[1]\n        sx = sizeofin[2]\n        sy = sizeofin[3]  \n\n        self.output = torch.zeros(ins,n*5,sx,sy, device = x.device)\n\n        for i in range(0,ins):\n\n\n            # ORIGINAL INPUT\n            oM = 0\n            oN = n\n            \n            self.output[i,oM:oN,0:sx,0:sy]= x[i].clone()\n            \n            # HORIZONTAL DIFFERENCE\n            oM = n\n            oN = 2*n\n\n            #area = self.output[i,oM:oN,0:sx-1,0:sy]\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(x[i,0:n,0:sx-1,0:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(-x[i,0:n,1:sx,0:sy])\n            \n            # VERTICAL DIFFERENCE\n            oM = 2*n\n            oN = 3*n\n\n            #area = ptr[oM:oN,0:sx,0:sy-1]\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(x[i,0:n,0:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(-x[i,0:n,0:sx,1:sy])\n            \n            # SOUTH EAST\n            oM = 3*n\n            oN = 4*n\n\n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            # SOUTH WEST\n            oM = 4*n\n            oN = 5*n\n           \n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            \n            \n\n        oM = n\n        oN = 5*n\n\n        \n        #Inplace error came from the line below\n        #self.output[0:ins,oM:oN,:,:] = self.output[0:ins,oM:oN].abs()\n        self.output[0:ins,oM:oN,:,:] = torch.abs(self.output[0:ins,oM:oN].clone().detach())\n        \n        #print(self.output)\n\n        return self.output\n","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:47:48.811217Z","iopub.execute_input":"2023-04-22T10:47:48.811788Z","iopub.status.idle":"2023-04-22T10:47:48.829594Z","shell.execute_reply.started":"2023-04-22T10:47:48.811751Z","shell.execute_reply":"2023-04-22T10:47:48.828261Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class DiffConv6(nn.Module):\n\n    def __init__(self):\n        super(DiffConv6, self).__init__()\n\n    def forward(self, x):\n        sizeofin = x.size()\n        \n        ins = sizeofin[0]\n        n = sizeofin[1]\n        sx = sizeofin[2]\n        sy = sizeofin[3]  \n\n        self.output = torch.zeros(ins,n*6,sx,sy, device = x.device)\n        dmax = x.max()\n        dmin = x.min()\n        \n        for i in range(0,ins):\n\n\n            # ORIGINAL INPUT\n            oM = 0\n            oN = n\n            \n            self.output[i,oM:oN,0:sx,0:sy]= x[i].clone()\n            \n            # HORIZONTAL DIFFERENCE\n            oM = n\n            oN = 2*n\n\n            #area = self.output[i,oM:oN,0:sx-1,0:sy]\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(x[i,0:n,0:sx-1,0:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy] = self.output[i,oM:oN,0:sx-1,0:sy].add(-x[i,0:n,1:sx,0:sy])\n            \n            # VERTICAL DIFFERENCE\n            oM = 2*n\n            oN = 3*n\n\n            #area = ptr[oM:oN,0:sx,0:sy-1]\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(x[i,0:n,0:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx,0:sy-1]=self.output[i,oM:oN,0:sx,0:sy-1].add(-x[i,0:n,0:sx,1:sy])\n            \n            # SOUTH EAST\n            oM = 3*n\n            oN = 4*n\n\n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            # SOUTH WEST\n            oM = 4*n\n            oN = 5*n\n           \n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1]=self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            \n            # RIGHT - SOUTH EAST - BOTTOM\n            oM = 5*n\n            oN = 6*n\n           \n            #area = ptr[oM:oN,0:sx-1,0:sy-1]\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(x[i,0:n,0:sx-1,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,0:sy-1])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,0:sx-1,1:sy])\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = self.output[i,oM:oN,0:sx-1,0:sy-1].add(-x[i,0:n,1:sx,1:sy])\n            \n            #SCALE [-765 to 255] to [0 to 255]\n            \n            amin = self.output[i,oM:oN,0:sx-1,0:sy-1].clone().detach().min()\n            amax = self.output[i,oM:oN,0:sx-1,0:sy-1].clone().detach().max()\n            # Scale: -255 to 85\n            self.output[i,oM:oN,0:sx-1,0:sy-1] = ( (self.output[i,oM:oN,0:sx-1,0:sy-1].clone().detach()) / 3 ).int()\n            \n\n        oM = n\n        oN = 6*n\n\n           \n        #self.signInputs = self.output.sign()\n        #self.signInputs[0:ins,0:n,:,:] = torch.ones(ins,n,sx,sy)\n        \n        #Inplace error came from the line below\n        #self.output[0:ins,oM:oN,:,:] = self.output[0:ins,oM:oN].abs()\n        self.output[0:ins,oM:oN,:,:] = torch.abs(self.output[0:ins,oM:oN].clone().detach())\n        \n        #self.output[0:ins,oM:oN,:,:] = torch.sqrt(self.output[0:ins,oM:oN] * self.output[0:ins,oM:oN].clone().detach())\n\n        #print(self.output)\n\n        return self.output","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:47:49.960244Z","iopub.execute_input":"2023-04-22T10:47:49.960641Z","iopub.status.idle":"2023-04-22T10:47:49.985694Z","shell.execute_reply.started":"2023-04-22T10:47:49.960605Z","shell.execute_reply":"2023-04-22T10:47:49.984355Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# <center> WandB Init </center>","metadata":{}},{"cell_type":"code","source":"# Set up Weights and Biases\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:47:51.639143Z","iopub.execute_input":"2023-04-22T10:47:51.640014Z","iopub.status.idle":"2023-04-22T10:47:57.667430Z","shell.execute_reply.started":"2023-04-22T10:47:51.639972Z","shell.execute_reply":"2023-04-22T10:47:57.666278Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# <center> DATASET </center>","metadata":{}},{"cell_type":"code","source":"# Define transforms for data preprocessing\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n])\n\n# Load CIFAR10 dataset\ntrain_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntest_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:48:05.068805Z","iopub.execute_input":"2023-04-22T10:48:05.069191Z","iopub.status.idle":"2023-04-22T10:48:12.556602Z","shell.execute_reply.started":"2023-04-22T10:48:05.069153Z","shell.execute_reply":"2023-04-22T10:48:12.555525Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/170498071 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6b1ba84aa0b474181c028f74474689f"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <center> Network Architectures </center>","metadata":{}},{"cell_type":"code","source":"multiplier = 8\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, 8*multiplier, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(8*multiplier)\n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.conv2 = nn.Conv2d(8*multiplier, 16*multiplier, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(16*multiplier)\n        \n        self.conv3 = nn.Conv2d(16*multiplier, 32*multiplier, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(32*multiplier)\n        \n        self.fc1 = nn.Linear(32*multiplier * 4 * 4, 128*multiplier)\n        self.dropout1 = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(128*multiplier, 64*multiplier)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.fc3 = nn.Linear(64*multiplier, 10)\n        \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x) # 16x16\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x) # 8x8\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x) # 4x4\n\n        x = x.view(-1, 32*multiplier * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:48:12.559051Z","iopub.execute_input":"2023-04-22T10:48:12.559457Z","iopub.status.idle":"2023-04-22T10:48:12.571235Z","shell.execute_reply.started":"2023-04-22T10:48:12.559418Z","shell.execute_reply":"2023-04-22T10:48:12.570210Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"m = CNN()\nsummary(m, (3, 32, 32))","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:48:12.572552Z","iopub.execute_input":"2023-04-22T10:48:12.573575Z","iopub.status.idle":"2023-04-22T10:48:21.308069Z","shell.execute_reply.started":"2023-04-22T10:48:12.573430Z","shell.execute_reply":"2023-04-22T10:48:21.306882Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─Conv2d: 1-1                            [-1, 64, 32, 32]          1,792\n├─BatchNorm2d: 1-2                       [-1, 64, 32, 32]          128\n├─MaxPool2d: 1-3                         [-1, 64, 16, 16]          --\n├─Conv2d: 1-4                            [-1, 128, 16, 16]         73,856\n├─BatchNorm2d: 1-5                       [-1, 128, 16, 16]         256\n├─MaxPool2d: 1-6                         [-1, 128, 8, 8]           --\n├─Conv2d: 1-7                            [-1, 256, 8, 8]           295,168\n├─BatchNorm2d: 1-8                       [-1, 256, 8, 8]           512\n├─MaxPool2d: 1-9                         [-1, 256, 4, 4]           --\n├─Linear: 1-10                           [-1, 1024]                4,195,328\n├─Dropout: 1-11                          [-1, 1024]                --\n├─Linear: 1-12                           [-1, 512]                 524,800\n├─Dropout: 1-13                          [-1, 512]                 --\n├─Linear: 1-14                           [-1, 10]                  5,130\n==========================================================================================\nTotal params: 5,096,970\nTrainable params: 5,096,970\nNon-trainable params: 0\nTotal mult-adds (M): 44.24\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 1.76\nParams size (MB): 19.44\nEstimated Total Size (MB): 21.22\n==========================================================================================\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─Conv2d: 1-1                            [-1, 64, 32, 32]          1,792\n├─BatchNorm2d: 1-2                       [-1, 64, 32, 32]          128\n├─MaxPool2d: 1-3                         [-1, 64, 16, 16]          --\n├─Conv2d: 1-4                            [-1, 128, 16, 16]         73,856\n├─BatchNorm2d: 1-5                       [-1, 128, 16, 16]         256\n├─MaxPool2d: 1-6                         [-1, 128, 8, 8]           --\n├─Conv2d: 1-7                            [-1, 256, 8, 8]           295,168\n├─BatchNorm2d: 1-8                       [-1, 256, 8, 8]           512\n├─MaxPool2d: 1-9                         [-1, 256, 4, 4]           --\n├─Linear: 1-10                           [-1, 1024]                4,195,328\n├─Dropout: 1-11                          [-1, 1024]                --\n├─Linear: 1-12                           [-1, 512]                 524,800\n├─Dropout: 1-13                          [-1, 512]                 --\n├─Linear: 1-14                           [-1, 10]                  5,130\n==========================================================================================\nTotal params: 5,096,970\nTrainable params: 5,096,970\nNon-trainable params: 0\nTotal mult-adds (M): 44.24\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 1.76\nParams size (MB): 19.44\nEstimated Total Size (MB): 21.22\n=========================================================================================="},"metadata":{}}]},{"cell_type":"code","source":"multiplier = 4\n\n# CNN with DiffConv4\nclass NetDiffConv4(nn.Module):\n    def __init__(self):\n        super(NetDiffConv4, self).__init__()\n        \n        self.diff = DiffConv4()\n        \n        self.conv1 = nn.Conv2d(12, 16*multiplier, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(16*multiplier)\n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.conv2 = nn.Conv2d(16*multiplier, 32*multiplier, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(32*multiplier)\n        \n        self.conv3 = nn.Conv2d(32*multiplier, 64*multiplier, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(64*multiplier)\n        \n        self.fc1 = nn.Linear(64*multiplier * 4 * 4, 256*multiplier)\n        self.dropout1 = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(256*multiplier, 128*multiplier)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.fc3 = nn.Linear(128*multiplier, 10)\n        \n    def forward(self, x):\n        x = self.diff(x)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x) # 16x16\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x) # 8x8\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x) # 4x4\n\n        x = x.view(-1, 64*multiplier * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x\n\n\n# CNN with DiffConv5\nclass NetDiffConv5(nn.Module):\n    def __init__(self):\n        super(NetDiffConv5, self).__init__()\n        self.diff = DiffConv5()\n        \n        self.conv1 = nn.Conv2d(15, 16*multiplier, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(16*multiplier)\n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.conv2 = nn.Conv2d(16*multiplier, 32*multiplier, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(32*multiplier)\n        \n        self.conv3 = nn.Conv2d(32*multiplier, 64*multiplier, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(64*multiplier)\n        \n        self.fc1 = nn.Linear(64*multiplier * 4 * 4, 256*multiplier)\n        self.dropout1 = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(256*multiplier, 128*multiplier)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.fc3 = nn.Linear(128*multiplier, 10)\n        \n    def forward(self, x):\n        x = self.diff(x)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x) # 16x16\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x) # 8x8\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x) # 4x4\n\n        x = x.view(-1, 64*multiplier * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x\n\n\n\n# CNN with DiffConv6\nclass NetDiffConv6(nn.Module):\n    def __init__(self):\n        super(NetDiffConv6, self).__init__()\n        self.diff = DiffConv6()\n\n        self.conv1 = nn.Conv2d(18, 16*multiplier, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(16*multiplier)\n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.conv2 = nn.Conv2d(16*multiplier, 32*multiplier, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(32*multiplier)\n        \n        self.conv3 = nn.Conv2d(32*multiplier, 64*multiplier, 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(64*multiplier)\n        \n        self.fc1 = nn.Linear(64*multiplier * 4 * 4, 256*multiplier)\n        self.dropout1 = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(256*multiplier, 128*multiplier)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.fc3 = nn.Linear(128*multiplier, 10)\n        \n    def forward(self, x):\n        x = self.diff(x)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x) # 16x16\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x) # 8x8\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x) # 4x4\n\n        x = x.view(-1, 64*multiplier * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:48:21.311518Z","iopub.execute_input":"2023-04-22T10:48:21.311815Z","iopub.status.idle":"2023-04-22T10:48:21.336719Z","shell.execute_reply.started":"2023-04-22T10:48:21.311781Z","shell.execute_reply":"2023-04-22T10:48:21.335612Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# <center> WandB Config </center>","metadata":{}},{"cell_type":"code","source":"sweep_config = {\n    'method': 'grid',\n    \n    'metric' : {\n        'name': 'val_loss',\n        'goal': 'minimize'\n    },\n    \n    'parameters' : {\n        'model' : {\n            'values': ['CNN', 'NetDiffConv4', 'NetDiffConv5', 'NetDiffConv6']\n                  }\n    }\n    \n    }\n\npprint.pprint(sweep_config)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:48:21.338364Z","iopub.execute_input":"2023-04-22T10:48:21.338768Z","iopub.status.idle":"2023-04-22T10:48:21.352607Z","shell.execute_reply.started":"2023-04-22T10:48:21.338731Z","shell.execute_reply":"2023-04-22T10:48:21.351547Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"{'method': 'grid',\n 'metric': {'goal': 'minimize', 'name': 'val_loss'},\n 'parameters': {'model': {'values': ['CNN',\n                                     'NetDiffConv4',\n                                     'NetDiffConv5',\n                                     'NetDiffConv6']}}}\n","output_type":"stream"}]},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep_config, project=\"Diffconv_Cifar10_3\")","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:48:21.353990Z","iopub.execute_input":"2023-04-22T10:48:21.354448Z","iopub.status.idle":"2023-04-22T10:48:21.606793Z","shell.execute_reply.started":"2023-04-22T10:48:21.354406Z","shell.execute_reply":"2023-04-22T10:48:21.605803Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Create sweep with ID: vkwu2aor\nSweep URL: https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <center> TRAINING ++ </center>","metadata":{}},{"cell_type":"code","source":"# Train loop\ndef train(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for inputs, targets in tqdm(dataloader, desc='Training', leave=False):\n        inputs, targets = inputs.to(device), targets.to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        # compute statistics\n        running_loss += loss.item() * inputs.size(0)\n        predicted = outputs.argmax(dim=1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n\n# Test loop\ndef test(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, targets in tqdm(dataloader, desc='Testing', leave=False):\n            inputs, targets = inputs.to(device), targets.to(device)\n\n            # forward\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n            # compute statistics\n            running_loss += loss.item() * inputs.size(0)\n            predicted = outputs.argmax(dim=1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:48:21.609316Z","iopub.execute_input":"2023-04-22T10:48:21.609959Z","iopub.status.idle":"2023-04-22T10:48:21.620749Z","shell.execute_reply.started":"2023-04-22T10:48:21.609921Z","shell.execute_reply":"2023-04-22T10:48:21.619715Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nlearning_rate = 0.0001\nnum_epochs = 30\n# optimizer = 'Adam'\nlr_step_size = 10\nlr_gamma = 0.1\nbetas = (0.85, 0.999)\namsgrad = True","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:48:21.622358Z","iopub.execute_input":"2023-04-22T10:48:21.622806Z","iopub.status.idle":"2023-04-22T10:48:21.631787Z","shell.execute_reply.started":"2023-04-22T10:48:21.622767Z","shell.execute_reply":"2023-04-22T10:48:21.630784Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def main(config = None):\n    \n    # Define data loaders\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n\n    # Train and evaluate models\n    with wandb.init(config = config):\n        config = wandb.config\n        model_name = config.model\n\n        if config.model == 'CNN':\n            model = CNN().to(device)\n        elif config.model == 'NetDiffConv4':\n            model = NetDiffConv4().to(device)\n        elif config.model == 'NetDiffConv5':\n            model = NetDiffConv5().to(device)\n        elif config.model == 'NetDiffConv6':\n            model = NetDiffConv6().to(device)\n\n        print(f'Training {model_name} model...')\n\n        optimizer = optim.Adam(model.parameters(),\n                               lr=learning_rate,\n                               betas = betas,\n                               amsgrad = amsgrad,\n                              )\n\n    # LEARNING RATE SCHEDULERS\n    #     scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=num_epochs//3, T_mult=2, eta_min=0)\n\n        criterion = nn.CrossEntropyLoss()\n        best_val_acc = 0.0\n        for epoch in range(1, num_epochs+1):\n            scheduler.step()\n            train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n            val_loss, val_acc = test(model, test_loader, criterion, device)\n            print(f'Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n\n            # log results to weights and biases\n            wandb.log({'train_loss': train_loss,\n                       'train_acc': train_acc,\n                       'val_loss': val_loss,\n                       'val_acc': val_acc})\n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                torch.save(model.state_dict(), f'{model_name}.pt')\n        print(f'{model_name} model finished training with best validation accuracy of {best_val_acc:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:48:21.633731Z","iopub.execute_input":"2023-04-22T10:48:21.634252Z","iopub.status.idle":"2023-04-22T10:48:21.647689Z","shell.execute_reply.started":"2023-04-22T10:48:21.634185Z","shell.execute_reply":"2023-04-22T10:48:21.646785Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"wandb.agent(sweep_id, main, count=4)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T10:48:21.651444Z","iopub.execute_input":"2023-04-22T10:48:21.651821Z","iopub.status.idle":"2023-04-22T12:59:34.491976Z","shell.execute_reply.started":"2023-04-22T10:48:21.651784Z","shell.execute_reply":"2023-04-22T12:59:34.490839Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0q47vtgl with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: CNN\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshiwayz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230422_104824-0q47vtgl</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/0q47vtgl' target=\"_blank\">azure-sweep-1</a></strong> to <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/0q47vtgl' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/0q47vtgl</a>"},"metadata":{}},{"name":"stdout","text":"Training CNN model...\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30, Train Loss: 1.5746, Train Acc: 0.4182, Val Loss: 1.2081, Val Acc: 0.5539\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/30, Train Loss: 1.2789, Train Acc: 0.5344, Val Loss: 1.0222, Val Acc: 0.6339\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/30, Train Loss: 1.1559, Train Acc: 0.5830, Val Loss: 0.9826, Val Acc: 0.6407\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/30, Train Loss: 1.0761, Train Acc: 0.6164, Val Loss: 0.8629, Val Acc: 0.6907\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/30, Train Loss: 1.0127, Train Acc: 0.6401, Val Loss: 0.8282, Val Acc: 0.7055\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/30, Train Loss: 0.9682, Train Acc: 0.6544, Val Loss: 0.8056, Val Acc: 0.7146\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/30, Train Loss: 0.9342, Train Acc: 0.6689, Val Loss: 0.7809, Val Acc: 0.7230\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/30, Train Loss: 0.9113, Train Acc: 0.6759, Val Loss: 0.7692, Val Acc: 0.7281\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/30, Train Loss: 0.9016, Train Acc: 0.6796, Val Loss: 0.7635, Val Acc: 0.7287\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/30, Train Loss: 0.9794, Train Acc: 0.6525, Val Loss: 0.8103, Val Acc: 0.7139\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/30, Train Loss: 0.9376, Train Acc: 0.6675, Val Loss: 0.7730, Val Acc: 0.7250\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/30, Train Loss: 0.9070, Train Acc: 0.6800, Val Loss: 0.7386, Val Acc: 0.7387\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/30, Train Loss: 0.8780, Train Acc: 0.6899, Val Loss: 0.7196, Val Acc: 0.7437\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/30, Train Loss: 0.8568, Train Acc: 0.6976, Val Loss: 0.7276, Val Acc: 0.7422\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/30, Train Loss: 0.8287, Train Acc: 0.7081, Val Loss: 0.7008, Val Acc: 0.7516\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/30, Train Loss: 0.8089, Train Acc: 0.7162, Val Loss: 0.6539, Val Acc: 0.7699\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/30, Train Loss: 0.7859, Train Acc: 0.7231, Val Loss: 0.6645, Val Acc: 0.7710\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/30, Train Loss: 0.7676, Train Acc: 0.7294, Val Loss: 0.6354, Val Acc: 0.7797\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/30, Train Loss: 0.7471, Train Acc: 0.7394, Val Loss: 0.6208, Val Acc: 0.7837\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/30, Train Loss: 0.7308, Train Acc: 0.7416, Val Loss: 0.6156, Val Acc: 0.7861\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21/30, Train Loss: 0.7129, Train Acc: 0.7488, Val Loss: 0.6056, Val Acc: 0.7914\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22/30, Train Loss: 0.7042, Train Acc: 0.7527, Val Loss: 0.5953, Val Acc: 0.7928\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23/30, Train Loss: 0.6912, Train Acc: 0.7575, Val Loss: 0.5844, Val Acc: 0.7980\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24/30, Train Loss: 0.6762, Train Acc: 0.7635, Val Loss: 0.5885, Val Acc: 0.7920\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25/30, Train Loss: 0.6693, Train Acc: 0.7648, Val Loss: 0.5753, Val Acc: 0.7994\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26/30, Train Loss: 0.6579, Train Acc: 0.7689, Val Loss: 0.5744, Val Acc: 0.7970\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27/30, Train Loss: 0.6578, Train Acc: 0.7696, Val Loss: 0.5733, Val Acc: 0.7996\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28/30, Train Loss: 0.6559, Train Acc: 0.7715, Val Loss: 0.5702, Val Acc: 0.7990\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29/30, Train Loss: 0.6476, Train Acc: 0.7734, Val Loss: 0.5664, Val Acc: 0.8033\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30/30, Train Loss: 0.7427, Train Acc: 0.7384, Val Loss: 0.6361, Val Acc: 0.7757\nCNN model finished training with best validation accuracy of 0.8033\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.073 MB of 0.073 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5a2f5b48a7f4de49a9c70df1acfec19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▃▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█████████▇</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▃▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>val_acc</td><td>▁▃▃▅▅▆▆▆▆▅▆▆▆▆▇▇▇▇▇██████████▇</td></tr><tr><td>val_loss</td><td>█▆▆▄▄▄▃▃▃▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.73842</td></tr><tr><td>train_loss</td><td>0.74272</td></tr><tr><td>val_acc</td><td>0.7757</td></tr><tr><td>val_loss</td><td>0.63606</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">azure-sweep-1</strong> at: <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/0q47vtgl' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/0q47vtgl</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230422_104824-0q47vtgl/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hokcc84w with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: NetDiffConv4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230422_111326-hokcc84w</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/hokcc84w' target=\"_blank\">sweepy-sweep-2</a></strong> to <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/hokcc84w' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/hokcc84w</a>"},"metadata":{}},{"name":"stdout","text":"Training NetDiffConv4 model...\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30, Train Loss: 1.4453, Train Acc: 0.4687, Val Loss: 1.0747, Val Acc: 0.6052\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/30, Train Loss: 1.0920, Train Acc: 0.6084, Val Loss: 0.8753, Val Acc: 0.6902\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/30, Train Loss: 0.9578, Train Acc: 0.6592, Val Loss: 0.7992, Val Acc: 0.7139\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/30, Train Loss: 0.8764, Train Acc: 0.6888, Val Loss: 0.7284, Val Acc: 0.7433\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/30, Train Loss: 0.8097, Train Acc: 0.7132, Val Loss: 0.6608, Val Acc: 0.7682\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/30, Train Loss: 0.7589, Train Acc: 0.7316, Val Loss: 0.6305, Val Acc: 0.7801\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/30, Train Loss: 0.7176, Train Acc: 0.7508, Val Loss: 0.6057, Val Acc: 0.7865\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/30, Train Loss: 0.6911, Train Acc: 0.7580, Val Loss: 0.5996, Val Acc: 0.7879\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/30, Train Loss: 0.6746, Train Acc: 0.7635, Val Loss: 0.5897, Val Acc: 0.7921\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/30, Train Loss: 0.7923, Train Acc: 0.7217, Val Loss: 0.6540, Val Acc: 0.7709\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/30, Train Loss: 0.7550, Train Acc: 0.7329, Val Loss: 0.6362, Val Acc: 0.7765\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/30, Train Loss: 0.7217, Train Acc: 0.7453, Val Loss: 0.6108, Val Acc: 0.7838\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/30, Train Loss: 0.6917, Train Acc: 0.7558, Val Loss: 0.5685, Val Acc: 0.8039\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/30, Train Loss: 0.6703, Train Acc: 0.7652, Val Loss: 0.5633, Val Acc: 0.8070\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/30, Train Loss: 0.6441, Train Acc: 0.7739, Val Loss: 0.5472, Val Acc: 0.8127\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/30, Train Loss: 0.6226, Train Acc: 0.7820, Val Loss: 0.5341, Val Acc: 0.8150\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/30, Train Loss: 0.6043, Train Acc: 0.7867, Val Loss: 0.5278, Val Acc: 0.8170\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/30, Train Loss: 0.5829, Train Acc: 0.7954, Val Loss: 0.5337, Val Acc: 0.8208\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/30, Train Loss: 0.5652, Train Acc: 0.8010, Val Loss: 0.4911, Val Acc: 0.8302\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/30, Train Loss: 0.5495, Train Acc: 0.8054, Val Loss: 0.4786, Val Acc: 0.8331\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21/30, Train Loss: 0.5279, Train Acc: 0.8139, Val Loss: 0.4770, Val Acc: 0.8364\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22/30, Train Loss: 0.5112, Train Acc: 0.8212, Val Loss: 0.4618, Val Acc: 0.8403\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23/30, Train Loss: 0.4977, Train Acc: 0.8259, Val Loss: 0.4621, Val Acc: 0.8432\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24/30, Train Loss: 0.4819, Train Acc: 0.8322, Val Loss: 0.4454, Val Acc: 0.8491\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25/30, Train Loss: 0.4678, Train Acc: 0.8352, Val Loss: 0.4422, Val Acc: 0.8496\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26/30, Train Loss: 0.4574, Train Acc: 0.8409, Val Loss: 0.4343, Val Acc: 0.8515\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27/30, Train Loss: 0.4527, Train Acc: 0.8405, Val Loss: 0.4349, Val Acc: 0.8525\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28/30, Train Loss: 0.4488, Train Acc: 0.8421, Val Loss: 0.4354, Val Acc: 0.8520\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29/30, Train Loss: 0.4457, Train Acc: 0.8426, Val Loss: 0.4322, Val Acc: 0.8547\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30/30, Train Loss: 0.5670, Train Acc: 0.8001, Val Loss: 0.5065, Val Acc: 0.8290\nNetDiffConv4 model finished training with best validation accuracy of 0.8547\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.086 MB of 0.086 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a5972b686bf41b2915cafc8978488a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇████████▇</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂</td></tr><tr><td>val_acc</td><td>▁▃▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████▇</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.80006</td></tr><tr><td>train_loss</td><td>0.56703</td></tr><tr><td>val_acc</td><td>0.829</td></tr><tr><td>val_loss</td><td>0.50647</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">sweepy-sweep-2</strong> at: <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/hokcc84w' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/hokcc84w</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230422_111326-hokcc84w/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0zcqlilp with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: NetDiffConv5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230422_114405-0zcqlilp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/0zcqlilp' target=\"_blank\">northern-sweep-3</a></strong> to <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/0zcqlilp' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/0zcqlilp</a>"},"metadata":{}},{"name":"stdout","text":"Training NetDiffConv5 model...\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30, Train Loss: 1.4464, Train Acc: 0.4696, Val Loss: 1.0077, Val Acc: 0.6384\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/30, Train Loss: 1.0763, Train Acc: 0.6139, Val Loss: 0.8288, Val Acc: 0.7030\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/30, Train Loss: 0.9430, Train Acc: 0.6653, Val Loss: 0.7665, Val Acc: 0.7293\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/30, Train Loss: 0.8634, Train Acc: 0.6933, Val Loss: 0.6926, Val Acc: 0.7521\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/30, Train Loss: 0.7895, Train Acc: 0.7210, Val Loss: 0.6744, Val Acc: 0.7659\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/30, Train Loss: 0.7393, Train Acc: 0.7403, Val Loss: 0.6164, Val Acc: 0.7852\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/30, Train Loss: 0.7009, Train Acc: 0.7524, Val Loss: 0.6058, Val Acc: 0.7872\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/30, Train Loss: 0.6762, Train Acc: 0.7606, Val Loss: 0.5846, Val Acc: 0.7935\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/30, Train Loss: 0.6590, Train Acc: 0.7656, Val Loss: 0.5751, Val Acc: 0.7980\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/30, Train Loss: 0.7724, Train Acc: 0.7295, Val Loss: 0.6520, Val Acc: 0.7718\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/30, Train Loss: 0.7341, Train Acc: 0.7409, Val Loss: 0.6067, Val Acc: 0.7892\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/30, Train Loss: 0.7134, Train Acc: 0.7509, Val Loss: 0.5747, Val Acc: 0.8005\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/30, Train Loss: 0.6799, Train Acc: 0.7607, Val Loss: 0.5900, Val Acc: 0.7931\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/30, Train Loss: 0.6518, Train Acc: 0.7707, Val Loss: 0.5501, Val Acc: 0.8111\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/30, Train Loss: 0.6319, Train Acc: 0.7789, Val Loss: 0.5335, Val Acc: 0.8179\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/30, Train Loss: 0.6136, Train Acc: 0.7830, Val Loss: 0.5245, Val Acc: 0.8199\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/30, Train Loss: 0.5858, Train Acc: 0.7941, Val Loss: 0.5173, Val Acc: 0.8249\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/30, Train Loss: 0.5738, Train Acc: 0.7986, Val Loss: 0.5057, Val Acc: 0.8267\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/30, Train Loss: 0.5594, Train Acc: 0.8037, Val Loss: 0.4748, Val Acc: 0.8360\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/30, Train Loss: 0.5305, Train Acc: 0.8135, Val Loss: 0.4910, Val Acc: 0.8361\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21/30, Train Loss: 0.5147, Train Acc: 0.8196, Val Loss: 0.4595, Val Acc: 0.8441\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22/30, Train Loss: 0.4986, Train Acc: 0.8257, Val Loss: 0.4498, Val Acc: 0.8449\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23/30, Train Loss: 0.4803, Train Acc: 0.8315, Val Loss: 0.4391, Val Acc: 0.8512\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24/30, Train Loss: 0.4709, Train Acc: 0.8339, Val Loss: 0.4368, Val Acc: 0.8505\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25/30, Train Loss: 0.4588, Train Acc: 0.8378, Val Loss: 0.4306, Val Acc: 0.8516\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26/30, Train Loss: 0.4493, Train Acc: 0.8425, Val Loss: 0.4312, Val Acc: 0.8526\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27/30, Train Loss: 0.4415, Train Acc: 0.8446, Val Loss: 0.4269, Val Acc: 0.8552\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28/30, Train Loss: 0.4377, Train Acc: 0.8458, Val Loss: 0.4231, Val Acc: 0.8549\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29/30, Train Loss: 0.4349, Train Acc: 0.8477, Val Loss: 0.4241, Val Acc: 0.8558\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30/30, Train Loss: 0.5550, Train Acc: 0.8047, Val Loss: 0.4853, Val Acc: 0.8321\nNetDiffConv5 model finished training with best validation accuracy of 0.8558\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.099 MB of 0.099 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89b461a9ddfa41cd962b8681e6cdaa69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████████▇</td></tr><tr><td>train_loss</td><td>█▅▅▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂</td></tr><tr><td>val_acc</td><td>▁▃▄▅▅▆▆▆▆▅▆▆▆▇▇▇▇▇▇▇█████████▇</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▃▃▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.80472</td></tr><tr><td>train_loss</td><td>0.55503</td></tr><tr><td>val_acc</td><td>0.8321</td></tr><tr><td>val_loss</td><td>0.48528</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">northern-sweep-3</strong> at: <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/0zcqlilp' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/0zcqlilp</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230422_114405-0zcqlilp/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5q1ph9jq with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: NetDiffConv6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230422_121713-5q1ph9jq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/5q1ph9jq' target=\"_blank\">fine-sweep-4</a></strong> to <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/sweeps/vkwu2aor</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/5q1ph9jq' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/5q1ph9jq</a>"},"metadata":{}},{"name":"stdout","text":"Training NetDiffConv6 model...\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30, Train Loss: 1.4402, Train Acc: 0.4710, Val Loss: 0.9967, Val Acc: 0.6418\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/30, Train Loss: 1.0764, Train Acc: 0.6141, Val Loss: 0.8690, Val Acc: 0.6889\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/30, Train Loss: 0.9361, Train Acc: 0.6655, Val Loss: 0.7674, Val Acc: 0.7276\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/30, Train Loss: 0.8521, Train Acc: 0.6989, Val Loss: 0.7059, Val Acc: 0.7532\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/30, Train Loss: 0.7914, Train Acc: 0.7188, Val Loss: 0.6394, Val Acc: 0.7738\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/30, Train Loss: 0.7373, Train Acc: 0.7377, Val Loss: 0.6115, Val Acc: 0.7848\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/30, Train Loss: 0.6941, Train Acc: 0.7537, Val Loss: 0.6010, Val Acc: 0.7900\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/30, Train Loss: 0.6689, Train Acc: 0.7633, Val Loss: 0.5764, Val Acc: 0.7968\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/30, Train Loss: 0.6506, Train Acc: 0.7703, Val Loss: 0.5697, Val Acc: 0.7991\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/30, Train Loss: 0.7672, Train Acc: 0.7268, Val Loss: 0.6672, Val Acc: 0.7656\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/30, Train Loss: 0.7344, Train Acc: 0.7407, Val Loss: 0.6017, Val Acc: 0.7913\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/30, Train Loss: 0.7013, Train Acc: 0.7525, Val Loss: 0.6030, Val Acc: 0.7849\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/30, Train Loss: 0.6760, Train Acc: 0.7626, Val Loss: 0.6316, Val Acc: 0.7855\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/30, Train Loss: 0.6505, Train Acc: 0.7712, Val Loss: 0.5895, Val Acc: 0.7997\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/30, Train Loss: 0.6240, Train Acc: 0.7811, Val Loss: 0.5362, Val Acc: 0.8153\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/30, Train Loss: 0.6045, Train Acc: 0.7876, Val Loss: 0.5325, Val Acc: 0.8176\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/30, Train Loss: 0.5830, Train Acc: 0.7965, Val Loss: 0.5122, Val Acc: 0.8250\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/30, Train Loss: 0.5603, Train Acc: 0.8028, Val Loss: 0.4997, Val Acc: 0.8322\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/30, Train Loss: 0.5376, Train Acc: 0.8112, Val Loss: 0.4755, Val Acc: 0.8364\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/30, Train Loss: 0.5247, Train Acc: 0.8148, Val Loss: 0.4885, Val Acc: 0.8342\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21/30, Train Loss: 0.5051, Train Acc: 0.8229, Val Loss: 0.4795, Val Acc: 0.8344\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22/30, Train Loss: 0.4940, Train Acc: 0.8276, Val Loss: 0.4701, Val Acc: 0.8421\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23/30, Train Loss: 0.4749, Train Acc: 0.8324, Val Loss: 0.4479, Val Acc: 0.8481\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24/30, Train Loss: 0.4597, Train Acc: 0.8389, Val Loss: 0.4477, Val Acc: 0.8484\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25/30, Train Loss: 0.4492, Train Acc: 0.8452, Val Loss: 0.4392, Val Acc: 0.8506\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26/30, Train Loss: 0.4369, Train Acc: 0.8454, Val Loss: 0.4347, Val Acc: 0.8530\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27/30, Train Loss: 0.4335, Train Acc: 0.8475, Val Loss: 0.4290, Val Acc: 0.8526\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28/30, Train Loss: 0.4294, Train Acc: 0.8497, Val Loss: 0.4283, Val Acc: 0.8558\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29/30, Train Loss: 0.4239, Train Acc: 0.8502, Val Loss: 0.4260, Val Acc: 0.8562\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30/30, Train Loss: 0.5384, Train Acc: 0.8112, Val Loss: 0.5372, Val Acc: 0.8185\nNetDiffConv6 model finished training with best validation accuracy of 0.8562\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.111 MB of 0.111 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4647fbe5fe034e4ba2804e98471cc6cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇████████▇</td></tr><tr><td>train_loss</td><td>█▅▅▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂</td></tr><tr><td>val_acc</td><td>▁▃▄▅▅▆▆▆▆▅▆▆▆▆▇▇▇▇▇▇▇████████▇</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▃▃▄▃▃▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.81124</td></tr><tr><td>train_loss</td><td>0.53841</td></tr><tr><td>val_acc</td><td>0.8185</td></tr><tr><td>val_loss</td><td>0.53723</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fine-sweep-4</strong> at: <a href='https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/5q1ph9jq' target=\"_blank\">https://wandb.ai/shiwayz/Diffconv_Cifar10_3/runs/5q1ph9jq</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230422_121713-5q1ph9jq/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T12:59:50.010185Z","iopub.execute_input":"2023-04-22T12:59:50.011132Z","iopub.status.idle":"2023-04-22T12:59:50.016037Z","shell.execute_reply.started":"2023-04-22T12:59:50.011093Z","shell.execute_reply":"2023-04-22T12:59:50.014980Z"},"trusted":true},"execution_count":18,"outputs":[]}]}